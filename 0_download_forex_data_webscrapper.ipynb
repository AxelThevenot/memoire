{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Téléchargement des données forex avec un Webscrapper\n",
    "## Objectif\n",
    "L'objectif de ce notebook est de permettre de récupérer l'historiques des données du forex dans le temps. Pour cela, nous utiliserons un webscrapper à l'aide de Selenium pour récupérer tout ce qui se trouve sur le site internet www.histdata.com qui met à disposition des données en libre téléchargement. \n",
    "\n",
    "## Un Webscrapper ? \n",
    "\n",
    "Nous utiliserons un webscrapper puisque les données sont disponibles mais sont difficiles d'accès. Du moins, l'historique des paires des devises est indépendante à chaque paire et chaque année. Donc avec environ 50 paires et 20 ans on peut s'attendre à répéter un bon millier de fois le même processus. D'où l'intérêt d'automatiser cela à l'aide d'un web scrapper. \n",
    "\n",
    "**Dans les prochains notebook nous reformaterons les données, ici, il ne s'agit que de les telécharger, ranger dans les bons dossiers puis les extraires des .zip**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies\n",
    "\n",
    "Avant toute chose, il est important d'avoir installé selenium. \n",
    "\n",
    "```\n",
    "pip install selenium\n",
    "```\n",
    "\n",
    "Ensuite, en fonction de votre navigateur télécharger le driver associé. Pour ma part, je suis sur chrome dont le lien de téléchargement est https://chromedriver.chromium.org/downloads. \n",
    "Extraire le driver si nécessaire et mettez le à la racine du notebook. \n",
    "Tout est fin prêt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # for path dirs and files\n",
    "import time  # to not to saturate the website \n",
    "import glob  # to recover the files after downloading them\n",
    "import shutil  # to move the files\n",
    "import zipfile  # to unzip files at the very end of the process\n",
    "\n",
    "\n",
    "# to automatize the scrapping\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouverture du driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-5c24f24948a3>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path_driver)\n"
     ]
    }
   ],
   "source": [
    "path_driver = os.path.join('.', 'chromedriver.exe')\n",
    "driver = webdriver.Chrome(path_driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des paires de devise\n",
    "\n",
    "Comme indiqué plus haut, on veut automatiser la récupération de l'historique des différentes paires de devise. Donc pour cela, il faut savoir quelles sont les devises alors on utilise selenium pour aller sur la page de listant les devises dont l'historique sous format ASCII des ticks M1 est présent. \n",
    "\n",
    "**Acceptez les cookies**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Free Forex Data – HistData.com\n"
     ]
    }
   ],
   "source": [
    "# open the webpage on which we can list all the pairs of currency\n",
    "driver.get(\"https://www.histdata.com/download-free-forex-data/?/ascii/1-minute-bar-quotes\")\n",
    "print(driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\athevenot\\Anaconda3\\lib\\site-packages\\selenium-4.0.0a7-py3.8.egg\\selenium\\webdriver\\remote\\webdriver.py:691: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
      "C:\\Users\\athevenot\\Anaconda3\\lib\\site-packages\\selenium-4.0.0a7-py3.8.egg\\selenium\\webdriver\\remote\\webelement.py:365: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 pairs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'EUR/USD, EUR/CHF, EUR/GBP, EUR/JPY, EUR/AUD, USD/CAD, USD/CHF, USD/JPY, USD/MXN, GBP/CHF, GBP/JPY, GBP/USD, AUD/JPY, AUD/USD, CHF/JPY, NZD/JPY, NZD/USD, XAU/USD, EUR/CAD, AUD/CAD, CAD/JPY, EUR/NZD, GRX/EUR, NZD/CAD, SGD/JPY, USD/HKD, USD/NOK, USD/TRY, XAU/AUD, AUD/CHF, AUX/AUD, EUR/HUF, EUR/PLN, FRX/EUR, HKX/HKD, NZD/CHF, SPX/USD, USD/HUF, USD/PLN, USD/ZAR, XAU/CHF, ZAR/JPY, BCO/USD, ETX/EUR, EUR/CZK, EUR/SEK, GBP/AUD, GBP/NZD, JPX/JPY, UDX/USD, USD/CZK, USD/SEK, WTI/USD, XAU/EUR, AUD/NZD, CAD/CHF, EUR/DKK, EUR/NOK, EUR/TRY, GBP/CAD, NSX/USD, UKX/GBP, USD/DKK, USD/SGD, XAG/USD, XAU/GBP'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recover all the pairs of currency from the table from the HTML page\n",
    "html_pair_table = driver.find_element_by_css_selector(\"#content > div > table > tbody\")\n",
    "html_pairs = html_pair_table.find_elements_by_tag_name(\"strong\")\n",
    "\n",
    "# isolate the text from the HTML\n",
    "pairs = [pair.text for pair in html_pairs]\n",
    "\n",
    "print(f\"Found {len(pairs)} pairs:\")\n",
    "', '.join(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement de l'historique disponible\n",
    "\n",
    "Nous avons donc la liste de paire de devises. Un rapide coup d'oeil et on remarque que les années disponibles se situent entre 2000 et 2020 à l'heure où j'écris ces lignes. Donc on navigue année par année, paire par paire pour tout télécharger. \n",
    "\n",
    "**J'ai ajouté plusieurs time.sleep() pour ne pas surcharger le siteweb. Le webscrapping n'est pas illégal mais limite alors il est préférable de respecter le site et de laisser du temps entre les différentes reqûetes. Cette cellule est longue donc tu peux aller te prendre un café ou deux (dure environ 3 heures)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading EUR/USD pair from 2000 to 2020 [1/66]...\n",
      "Downloading EUR/CHF pair from 2000 to 2020 [2/66]...\n",
      "Downloading EUR/GBP pair from 2000 to 2020 [3/66]...\n",
      "Downloading EUR/JPY pair from 2000 to 2020 [4/66]...\n",
      "Downloading EUR/AUD pair from 2000 to 2020 [5/66]...\n",
      "Downloading USD/CAD pair from 2000 to 2020 [6/66]...\n",
      "Downloading USD/CHF pair from 2000 to 2020 [7/66]...\n",
      "Downloading USD/JPY pair from 2000 to 2020 [8/66]...\n",
      "Downloading USD/MXN pair from 2000 to 2020 [9/66]...\n",
      "Downloading GBP/CHF pair from 2000 to 2020 [10/66]...\n",
      "Downloading GBP/JPY pair from 2000 to 2020 [11/66]...\n",
      "Downloading GBP/USD pair from 2000 to 2020 [12/66]...\n",
      "Downloading AUD/JPY pair from 2000 to 2020 [13/66]...\n",
      "Downloading AUD/USD pair from 2000 to 2020 [14/66]...\n",
      "Downloading CHF/JPY pair from 2000 to 2020 [15/66]...\n",
      "Downloading NZD/JPY pair from 2000 to 2020 [16/66]...\n",
      "Downloading NZD/USD pair from 2000 to 2020 [17/66]...\n",
      "Downloading XAU/USD pair from 2000 to 2020 [18/66]...\n",
      "Downloading EUR/CAD pair from 2000 to 2020 [19/66]...\n",
      "Downloading AUD/CAD pair from 2000 to 2020 [20/66]...\n",
      "Downloading CAD/JPY pair from 2000 to 2020 [21/66]...\n",
      "Downloading EUR/NZD pair from 2000 to 2020 [22/66]...\n",
      "Downloading GRX/EUR pair from 2000 to 2020 [23/66]...\n",
      "Downloading NZD/CAD pair from 2000 to 2020 [24/66]...\n",
      "Downloading SGD/JPY pair from 2000 to 2020 [25/66]...\n",
      "Downloading USD/HKD pair from 2000 to 2020 [26/66]...\n",
      "Downloading USD/NOK pair from 2000 to 2020 [27/66]...\n",
      "Downloading USD/TRY pair from 2000 to 2020 [28/66]...\n",
      "Downloading XAU/AUD pair from 2000 to 2020 [29/66]...\n",
      "Downloading AUD/CHF pair from 2000 to 2020 [30/66]...\n",
      "Downloading AUX/AUD pair from 2000 to 2020 [31/66]...\n",
      "Downloading EUR/HUF pair from 2000 to 2020 [32/66]...\n",
      "Downloading EUR/PLN pair from 2000 to 2020 [33/66]...\n",
      "Downloading FRX/EUR pair from 2000 to 2020 [34/66]...\n",
      "Downloading HKX/HKD pair from 2000 to 2020 [35/66]...\n",
      "Downloading NZD/CHF pair from 2000 to 2020 [36/66]...\n",
      "Downloading SPX/USD pair from 2000 to 2020 [37/66]...\n",
      "Downloading USD/HUF pair from 2000 to 2020 [38/66]...\n",
      "Downloading USD/PLN pair from 2000 to 2020 [39/66]...\n",
      "Downloading USD/ZAR pair from 2000 to 2020 [40/66]...\n",
      "Downloading XAU/CHF pair from 2000 to 2020 [41/66]...\n",
      "Downloading ZAR/JPY pair from 2000 to 2020 [42/66]...\n",
      "Downloading BCO/USD pair from 2000 to 2020 [43/66]...\n",
      "Downloading ETX/EUR pair from 2000 to 2020 [44/66]...\n",
      "Downloading EUR/CZK pair from 2000 to 2020 [45/66]...\n",
      "Downloading EUR/SEK pair from 2000 to 2020 [46/66]...\n",
      "Downloading GBP/AUD pair from 2000 to 2020 [47/66]...\n",
      "Downloading GBP/NZD pair from 2000 to 2020 [48/66]...\n",
      "Downloading JPX/JPY pair from 2000 to 2020 [49/66]...\n",
      "Downloading UDX/USD pair from 2000 to 2020 [50/66]...\n",
      "Downloading USD/CZK pair from 2000 to 2020 [51/66]...\n",
      "Downloading USD/SEK pair from 2000 to 2020 [52/66]...\n",
      "Downloading WTI/USD pair from 2000 to 2020 [53/66]...\n",
      "Downloading XAU/EUR pair from 2000 to 2020 [54/66]...\n",
      "Downloading AUD/NZD pair from 2000 to 2020 [55/66]...\n",
      "Downloading CAD/CHF pair from 2000 to 2020 [56/66]...\n",
      "Downloading EUR/DKK pair from 2000 to 2020 [57/66]...\n",
      "Downloading EUR/NOK pair from 2000 to 2020 [58/66]...\n",
      "Downloading EUR/TRY pair from 2000 to 2020 [59/66]...\n",
      "Downloading GBP/CAD pair from 2000 to 2020 [60/66]...\n",
      "Downloading NSX/USD pair from 2000 to 2020 [61/66]...\n",
      "Downloading UKX/GBP pair from 2000 to 2020 [62/66]...\n",
      "Downloading USD/DKK pair from 2000 to 2020 [63/66]...\n",
      "Downloading USD/SGD pair from 2000 to 2020 [64/66]...\n",
      "Downloading XAG/USD pair from 2000 to 2020 [65/66]...\n",
      "Downloading XAU/GBP pair from 2000 to 2020 [66/66]...\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://www.histdata.com/download-free-forex-historical-data/?/ascii/1-minute-bar-quotes'\n",
    "years = range(2000, 2020 + 1)\n",
    "\n",
    "# for each pair and year, download the historical data and status report file\n",
    "for i, pair in enumerate(pairs):\n",
    "    print(f'Downloading {pair} pair from {years[0]} to {years[-1]} [{i+1}/{len(pairs)}]...')\n",
    "\n",
    "    \n",
    "    for year in years:\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # get the url corresponding to (pair, year)\n",
    "        pair = pair.replace('/', '')\n",
    "        suffix = f'{pair.lower()}/{year}'\n",
    "        url = f'{base_url}/{suffix}'\n",
    "        \n",
    "        # go to the right url\n",
    "        driver.get(url)\n",
    "        \n",
    "        # click to download the historical data if exists\n",
    "        try:\n",
    "            hist_data_button = driver.find_element_by_xpath(f\"//a[@id='a_file']\")\n",
    "            hist_data_button.click()\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # click to download the status report if exists\n",
    "        try:\n",
    "            status_file = driver.find_element_by_xpath(f\"//a[@id='a_status']\")\n",
    "            status_file.click()\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rangement des fichiers téléchargées. \n",
    "\n",
    "Lors de notre téléchargement nous avons téléchargé tous le fichiers des paires de devise et par année. Pour chacun de ces couples on a un fichier de report de status lors de problèmes et un fichier avec l'historique des données. \n",
    "Tous ces fichiers sont dans le dossier téléchargement. Ce que l'on veut c'est pouvoir regreouper tous les fichiers dans des dossiers par paire de devise.\n",
    "\n",
    "\n",
    "Par sécurité, on créer alors les dossiers suivants s'il n'existent pas encore:\n",
    "\n",
    "```\n",
    ".data/\n",
    "|\n",
    "|__EURUSD/\n",
    "|  |\n",
    "|  |__histdata/\n",
    "|  |\n",
    "|  |__status/\n",
    "|\n",
    "|__EURUSD/\n",
    "|  |\n",
    "|  |__histdata/\n",
    "|  |\n",
    "|  |__status/\n",
    "|\n",
    "...\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root data folder\n",
    "data_dir = os.path.join('.', 'data')\n",
    "\n",
    "# directories to create if they not already exist\n",
    "directories_to_ensure = [data_dir]\n",
    "\n",
    "for pair in pairs:\n",
    "    pair = pair.replace('/', '')\n",
    "    # root pair folder and its historical folder and status folder\n",
    "    pair_dir = os.path.join(data_dir, pair)\n",
    "    pair_dir_histdata = os.path.join(pair_dir, 'histdata')\n",
    "    pair_dir_status = os.path.join(pair_dir, 'status')\n",
    "    \n",
    "    # append these 3 directories of this pair to the dir to ensure\n",
    "    directories_to_ensure.append(pair_dir)\n",
    "    directories_to_ensure.append(pair_dir_histdata)\n",
    "    directories_to_ensure.append(pair_dir_status)\n",
    "\n",
    "# now create every directory listed if it does not exist yet\n",
    "for directory in directories_to_ensure:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et maintenant qu'on est sûr que les dossiers existent pour chaque paire de devise alors on peut déplacer tous nos fichiers du dossier téléchargements aux dossiers des paires respectives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_root = r'C:/Users/athevenot/Downloads'\n",
    "\n",
    "dl_files = glob.glob(os.path.join(download_root, 'HISTDATA*'))\n",
    "\n",
    "for file in dl_files:\n",
    "    *_, filename = file.split(os.sep)\n",
    "    filename_without_extention, extension = filename.split('.')\n",
    "    \n",
    "    *_, pair, tick_year = filename_without_extention.split('_')\n",
    "    \n",
    "    file_data = 'histdata' if extension == 'zip' else 'status'\n",
    "    \n",
    "    new_dir = os.path.join('.', 'data', pair, file_data)\n",
    "    shutil.move(file, new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification des téléchargement\n",
    "Pour vérifier que les téléchargements se sont bien déroulés on va effectuer une vérification simple. Le but étant pour chaque paire de devise, de vérifier que les années des fichiers se suivent. \n",
    "\n",
    "Si ce n'est pas le cas on pourra corriger cela en effectuant les opérations précédentes de façon manuelle.\n",
    "\n",
    "On vérifie aussi que le nombre de fichier ne soit pas égal à 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is global error\n"
     ]
    }
   ],
   "source": [
    "# for each folder of each pair \n",
    "# we check the year of the files are following\n",
    "global_error = False\n",
    "\n",
    "for pair in pairs:\n",
    "    pair = pair.replace('/', '')\n",
    "    for folder in ['histdata', 'status']:\n",
    "        \n",
    "        # get all the years in a list from files\n",
    "        files = glob.glob(os.path.join('.', 'data', pair, folder, '*'))\n",
    "\n",
    "        # check there at least one file\n",
    "        if not len(files):\n",
    "            print(f'There is no file for the {pair} pair in {folder}:')\n",
    "            global_error = True\n",
    "\n",
    "        \n",
    "        \n",
    "        filenames = [f.split(os.sep)[-1].split('.')[0] for f in files]\n",
    "        years = [int(f[-4:]) for f in filenames]\n",
    "        \n",
    "        # sort the years ascendingly\n",
    "        years = list(sorted(years))\n",
    "                \n",
    "        # catch if there is a gap between year\n",
    "        error = False\n",
    "        for y_0, y_1 in zip(years[:-1], years[1:]):\n",
    "            if y_1 - y_0 != 1:\n",
    "                error = True\n",
    "                global_error = True\n",
    "                \n",
    "        # display years of the given pair and folder in case of an error\n",
    "        if error:\n",
    "            print(f'There is an error for the {pair} pair in {folder}:')\n",
    "            print(years)\n",
    "\n",
    "        \n",
    "global_error = ' at least one' * global_error\n",
    "print(f'There is{global_error} global error')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction des données\n",
    "\n",
    "On peut maintenant extraire tous les fichiers zip des différents dossiers (pas besoin de les supprimer ça ne prend pas beaucoup de place mais on pourrait en effet le faire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in pairs:\n",
    "    pair = pair.replace('/', '')\n",
    "    target_folder = os.path.join('.', 'data', pair, 'histdata')\n",
    "    # get all the years in a list from files\n",
    "    files_to_unzip = glob.glob(os.path.join(target_folder, '*.zip')) \n",
    "\n",
    "    for file in files_to_unzip:\n",
    "\n",
    "        with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(target_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
