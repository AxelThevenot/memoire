{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10_model_gpt2_training","provenance":[{"file_id":"144MdX5aLqrQ3-YW-po81CQMrD6kpgpYh","timestamp":1621975266022},{"file_id":"15qBZx5y9rdaQSyWpsreMDnTiZ5IlN0zD","timestamp":1589761169433},{"file_id":"1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce","timestamp":1589676386656},{"file_id":"1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK","timestamp":1555602712120}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"cb3adbfdbe7f4135a1810eaa2f3a81fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_599a74cc7d6841ce9c6bac43dad99d23","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e604274a113c41d685bed7cc0d7f5478","IPY_MODEL_f9db9772eb7842af98470415be237a14"]}},"599a74cc7d6841ce9c6bac43dad99d23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"e604274a113c41d685bed7cc0d7f5478":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7e029a866d4d48ec98cb966a1072da3e","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":25646,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25646,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d07cb0b54aef4d3a9bccc683da4ebb09"}},"f9db9772eb7842af98470415be237a14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_820d7612e1524eb893f255cd04da0c77","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25646/25646 [00:12&lt;00:00, 1995.10it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d2855022b5574829a205ac46a22254ed"}},"7e029a866d4d48ec98cb966a1072da3e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d07cb0b54aef4d3a9bccc683da4ebb09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"820d7612e1524eb893f255cd04da0c77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d2855022b5574829a205ac46a22254ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"43af99b592ff46c4914f4d14b3806a22":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5f54933a321f45d3baa12d4fffbbe35c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_49133d4ac4e649858d16975a6dc06a5f","IPY_MODEL_ca33419d51954f4c8a3c82254639c9a1"]}},"5f54933a321f45d3baa12d4fffbbe35c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"49133d4ac4e649858d16975a6dc06a5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_243932c18af449e08765e66a3962f027","_dom_classes":[],"description":"Loss: 0.081 — Avg: 0.080 — GPU Mem: 4777 MB:  99%","_model_name":"FloatProgressModel","bar_style":"","max":128230,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":126620,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b65a5599981843cf8b7c140474361c9a"}},"ca33419d51954f4c8a3c82254639c9a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_49c18fa827974adeac4f90d98647d233","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 126620/128230 [6:51:51&lt;05:14,  5.12it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_28f53b0c56ec4b6cb8788c0825eca8c3"}},"243932c18af449e08765e66a3962f027":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b65a5599981843cf8b7c140474361c9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49c18fa827974adeac4f90d98647d233":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"28f53b0c56ec4b6cb8788c0825eca8c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f050c2bc02c4841a33f90cc6a02bacc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_229e97fc3f3044ce822422c2a2447a39","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bcf51d5fecee444ebbb6fe4fc077e7e9","IPY_MODEL_ec51175c8bbd41f0934ccb15006452c4"]}},"229e97fc3f3044ce822422c2a2447a39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bcf51d5fecee444ebbb6fe4fc077e7e9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e82a60196ca840ba9fde7fcaab322b8b","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e3009893e58845f5a1bd631921f32e62"}},"ec51175c8bbd41f0934ccb15006452c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6204e958e12f4cde83fb1719c1630551","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [00:29&lt;00:00, 33.74it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_124b2727871f45fa9c250ace69e56300"}},"e82a60196ca840ba9fde7fcaab322b8b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e3009893e58845f5a1bd631921f32e62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6204e958e12f4cde83fb1719c1630551":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"124b2727871f45fa9c250ace69e56300":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6463d3bdaf134ff5944d335b7505844e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5b3554dd4eb8486bb9d5079d10b82950","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f6dce16c05c8481a9394803928c59ebc","IPY_MODEL_b6f567648d1142fd86ca16fcba8aa297"]}},"5b3554dd4eb8486bb9d5079d10b82950":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f6dce16c05c8481a9394803928c59ebc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_35b723c5289c4f59834133ffbc4aac73","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_786f685657d949f491f5b85b727a34ee"}},"b6f567648d1142fd86ca16fcba8aa297":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3508707863a94cb682c0bbd6de9682b2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [00:29&lt;00:00, 33.96it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a38268194b1d42cdad12fcf7aa2ba720"}},"35b723c5289c4f59834133ffbc4aac73":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"786f685657d949f491f5b85b727a34ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3508707863a94cb682c0bbd6de9682b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a38268194b1d42cdad12fcf7aa2ba720":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a01263a43ba84679a10b184b8b8b62fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4bc450fd005d4769aaa745a94ce2a6e3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_06edd28fd3424bf481135eb240a952fb","IPY_MODEL_d5e39d3761a04e01934d3b68f6766ef9"]}},"4bc450fd005d4769aaa745a94ce2a6e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"06edd28fd3424bf481135eb240a952fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_28579590db664d3db5dd299f86d89687","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2ebb28f4b07547d4ae42638638b7cc01"}},"d5e39d3761a04e01934d3b68f6766ef9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2ff342b1b23e46b18eefce4a2208493d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [00:29&lt;00:00, 33.42it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c42653e1ec904262881fd07733f5fff2"}},"28579590db664d3db5dd299f86d89687":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2ebb28f4b07547d4ae42638638b7cc01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ff342b1b23e46b18eefce4a2208493d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c42653e1ec904262881fd07733f5fff2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"586d5cf1054846b586549b86013efafd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5581f66bb872463890720232663d730a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a479d17319fd42bc9fc7904d7a7ff55f","IPY_MODEL_5b9010cc291a4b99bc86ba9b3e0725cf"]}},"5581f66bb872463890720232663d730a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a479d17319fd42bc9fc7904d7a7ff55f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_28012133664b437d9fe23cf40075ab4d","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c02c4826dcd14f4e83042bf7d7464c61"}},"5b9010cc291a4b99bc86ba9b3e0725cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2002ad6b9f524b83b330f7409be54250","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [00:29&lt;00:00, 33.89it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_494d036247c5407d8479fa65e02fd25f"}},"28012133664b437d9fe23cf40075ab4d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c02c4826dcd14f4e83042bf7d7464c61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2002ad6b9f524b83b330f7409be54250":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"494d036247c5407d8479fa65e02fd25f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9c126ac084e45f7a55b9435c2c9d2bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5da581e7c4734f41a186c25b8d48c58f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_db2190bbdbf04f1fae54032f61fef912","IPY_MODEL_8d695275ac4c471aaf0910e749ea71d5"]}},"5da581e7c4734f41a186c25b8d48c58f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db2190bbdbf04f1fae54032f61fef912":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_01250eb1d1b34f3f92453966048734d1","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_919e4cc6ea70431d8a1360e9bf592152"}},"8d695275ac4c471aaf0910e749ea71d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c67a09fc7d1a481fad6b764ebd7bec4d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [00:29&lt;00:00, 34.00it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7bb119334b554db89fa59dc67a26cdc8"}},"01250eb1d1b34f3f92453966048734d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"919e4cc6ea70431d8a1360e9bf592152":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c67a09fc7d1a481fad6b764ebd7bec4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7bb119334b554db89fa59dc67a26cdc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"H7LoMj4GA4n_"},"source":["#  aitextgen — Train a Custom GPT-2 Model + Tokenizer w/ GPU\n","\n","by [Max Woolf](https://minimaxir.com)\n","\n","*Last updated: May 16th, 2021 (aitextgen v0.5.2)*\n","\n","Train a custom GPT-2 model **for free on a GPU using Colaboratory** using `aitextgen`!\n","\n","It's recommended to only create a model from scratch if you really need to do so; otherwise, [finetuning 124M](https://colab.research.google.com/drive/15qBZx5y9rdaQSyWpsreMDnTiZ5IlN0zD?usp=sharing) may give you better results.\n","\n","For more about `aitextgen`, you can visit [this GitHub repository](https://github.com/minimaxir/aitextgen) or [read the documentation](https://docs.aitextgen.io/).\n","\n","\n","To get started:\n","\n","1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n","2. Run the cells below:\n"]},{"cell_type":"code","metadata":{"id":"KBkpRgBCBS2_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623655742146,"user_tz":-120,"elapsed":28060,"user":{"displayName":"axel arceuil","photoUrl":"","userId":"13030900473482598123"}},"outputId":"5df353f2-889a-4624-c1e6-26f936f911be"},"source":["!pip install -q aitextgen\n","\n","import logging\n","logging.basicConfig(\n","        format=\"%(asctime)s — %(levelname)s — %(name)s — %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        level=logging.INFO\n","    )\n","\n","from aitextgen import aitextgen\n","from aitextgen.colab import mount_gdrive, copy_file_from_gdrive\n","from aitextgen.TokenDataset import TokenDataset, merge_datasets\n","from aitextgen.utils import build_gpt2_config\n","from aitextgen.tokenizers import train_tokenizer"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 573kB 4.4MB/s \n","\u001b[K     |████████████████████████████████| 2.3MB 17.6MB/s \n","\u001b[K     |████████████████████████████████| 92kB 9.3MB/s \n","\u001b[K     |████████████████████████████████| 808kB 33.9MB/s \n","\u001b[K     |████████████████████████████████| 3.3MB 37.0MB/s \n","\u001b[K     |████████████████████████████████| 901kB 35.9MB/s \n","\u001b[K     |████████████████████████████████| 829kB 34.0MB/s \n","\u001b[K     |████████████████████████████████| 276kB 34.6MB/s \n","\u001b[K     |████████████████████████████████| 112kB 41.6MB/s \n","\u001b[K     |████████████████████████████████| 10.6MB 36.1MB/s \n","\u001b[K     |████████████████████████████████| 645kB 22.2MB/s \n","\u001b[K     |████████████████████████████████| 1.3MB 36.4MB/s \n","\u001b[K     |████████████████████████████████| 143kB 36.8MB/s \n","\u001b[K     |████████████████████████████████| 296kB 38.0MB/s \n","\u001b[?25h  Building wheel for aitextgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: tensorflow 2.5.0 has requirement tensorboard~=2.5, but you'll have tensorboard 2.4.1 which is incompatible.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Bj2IJLHP3KwE"},"source":["## GPU\n","\n","Colaboratory uses a Nvidia P4, an Nvidia T4, or an Nvidia P100 GPU. For finetuning GPT-2 124M, any of these GPUs will be fine, but for text generation, a T4 or a P100 is ideal since they have more VRAM.\n","\n","You can verify which GPU is active by running the cell below. If you want to try for a different GPU, go to **Runtime -> Factory Reset Runtime**."]},{"cell_type":"code","metadata":{"id":"sUmTooTW3osf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623655742150,"user_tz":-120,"elapsed":23,"user":{"displayName":"axel arceuil","photoUrl":"","userId":"13030900473482598123"}},"outputId":"d5dfce2a-9f2a-4b84-dc72-c8da0b5d5b1d"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Jun 14 07:29:03 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N8KXuKWzQSsN"},"source":["## Mounting Google Drive\n","\n","The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n","\n","Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"]},{"cell_type":"code","metadata":{"id":"puq4iC6vUAHc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623655776491,"user_tz":-120,"elapsed":34356,"user":{"displayName":"axel arceuil","photoUrl":"","userId":"13030900473482598123"}},"outputId":"568ac566-1dae-4109-831f-c0ff372b14a9"},"source":["mount_gdrive()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BT__brhBCvJu"},"source":["## Uploading a Text File to be Trained to Colaboratory\n","\n","In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n","\n","![alt text](https://i.imgur.com/w3wvHhR.png)\n","\n","Upload **any smaller text file** (for example, [a text file of Shakespeare plays](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt)) and update the file name in the cell below, then run the cell."]},{"cell_type":"code","metadata":{"id":"6OFnPCLADfll"},"source":["file_name = \"/content/drive/MyDrive/A5/Mémoire/notebooks/data/tokenized_training_data.csv\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HeeSKtNWUedE"},"source":["If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."]},{"cell_type":"code","metadata":{"id":"-Z6okFD8VKtS"},"source":["# copy_file_from_gdrive(file_name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J98wNTISLXqT"},"source":["## Training the Tokenizer\n","\n","Now we can train a Byte-Pair Encoding tokenizer on the dataset we just downloaded. The `train_tokenizer()` function wraps the training method for the `tokenizer` package from Huggingface.\n","\n","After the training is completed, this will save one file: **aitextgen.tokenizer.json**, which is needed to rebuild the tokenizer."]},{"cell_type":"markdown","metadata":{"id":"03lpNOUPTT5-"},"source":["```python \n","def train_tokenizer(\n","    files: Union[str, List[str]],\n","    dropout: float = None,\n","    vocab_size: int = 1000,\n","    min_frequency: int = 2,\n","    prefix: str = \"aitextgen\",\n","    save_path: str = \"\",\n","    added_tokens: List[str] = [],\n","    bos_token: str = \"<|endoftext|>\",\n","    eos_token: str = \"<|endoftext|>\",\n","    unk_token: str = \"<|endoftext|>\",\n","    serialize: bool = True,\n","    trim_offsets: bool = True,\n",") -> None:\n","    \"\"\"\n","    Tokenizes the text(s) as a tokenizer, wrapping the tokenizer package.\n","    See: https://huggingface.co/blog/how-to-train\n","    For consistency, this function makes opinionated assuptions.\n","    :param files: path to file(s) to train tokenizer on\n","    :param dropout: Training dropout\n","    :param vocab_size: Final vocabulary size\n","    :param min_frequency: Minimum number of occurences to add to vocab\n","    :param prefix: File name prefix of the final tokenizer\n","    :param save_path: Where to save the final tokenizer\n","    :param added_tokens: List of tokens to add to the tokenizer (currently not working)\n","    :param bos_token: Beginning-of-string special token\n","    :param eos_token: End-of-string special token\n","    :param unk_token: Unknown special token\n","    \"\"\"\n","```"]},{"cell_type":"code","metadata":{"id":"WQydnNzOUrNW"},"source":["VOCAB_SIZE = 1000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5brMzdmzLom3"},"source":["train_tokenizer(file_name, vocab_size=VOCAB_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KP4keZ36LxYl"},"source":["## Specify a Model Configuration\n","\n","You can use `build_gpt2_config` to specify a model configuration. You most likely will want to adjust `max_length` (context window size) and `n_embd` (embedding size).\n","\n","The config used here is the one used to build a [demo Reddit](https://github.com/minimaxir/aitextgen/blob/master/notebooks/reddit_demo.ipynb) model."]},{"cell_type":"markdown","metadata":{"id":"f0hV5GloTncj"},"source":["```python\n","def build_gpt2_config(\n","    vocab_size: int = 10000,\n","    bos_token_id: int = 0,\n","    eos_token_id: int = 0,\n","    max_length: int = 1024,\n","    dropout: float = 0.0,\n","    **kwargs\n","):\n","    \"\"\"\n","    Builds a custom GPT-2 config based on a given Transformers config,\n","    with a few more user-friendly aliases.\n","    \"\"\"\n","```"]},{"cell_type":"code","metadata":{"id":"GfbexWtKMaQB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623655787882,"user_tz":-120,"elapsed":20,"user":{"displayName":"axel arceuil","photoUrl":"","userId":"13030900473482598123"}},"outputId":"18e0e2a3-4687-4f6c-ec4f-efbaa626ab91"},"source":["config = build_gpt2_config(vocab_size=VOCAB_SIZE, max_length=350)\n","config"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"attn_pdrop\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 0,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 350,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 350,\n","  \"resid_pdrop\": 0.0,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.0,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.6.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 1000\n","}"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"ZABdZ-FcMmtA"},"source":["## Instantiating Your Custom GPT-2 Model\n","\n","Pass all the information to `aitextgen()` and you're good to go!"]},{"cell_type":"code","metadata":{"id":"AOfP_Rc9MvsZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623655797498,"user_tz":-120,"elapsed":9625,"user":{"displayName":"axel arceuil","photoUrl":"","userId":"13030900473482598123"}},"outputId":"970db87a-ceef-47a6-cb79-a939e3673f33"},"source":["ai = aitextgen(config=config,\n","               tokenizer_file=\"aitextgen.tokenizer.json\",\n","               to_gpu=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["06/14/2021 07:29:49 — INFO — aitextgen — Constructing model from provided config.\n","06/14/2021 07:29:52 — INFO — aitextgen — GPT2 loaded with 86M parameters.\n","06/14/2021 07:29:52 — INFO — aitextgen — Using a custom tokenizer.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"xHQhFvDfM7vk"},"source":["Generated output from it will be effectively random, for now."]},{"cell_type":"code","metadata":{"id":"Zo4PiSa1NA6j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623655801697,"user_tz":-120,"elapsed":4211,"user":{"displayName":"axel arceuil","photoUrl":"","userId":"13030900473482598123"}},"outputId":"fc5ac49a-d865-4ee7-9fd9-a1d2e0f3cd62"},"source":["ai.generate(5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":[") 697� 718 362 410 587 477 444� 78547 362 658 542 362N 362 754 302 15 245 730� 545.\u0012 245 386� 376 470} 403 518 376 806� 205� 386 58��� 386 376 905 727� 302 489� 658 523 658 239 15 658 651 730� 545 365 223 607 237� 727 245) 380 58 718 380� 905� 569 730 469 523 680 905) 730 628�\n"," 523 458 380 604 302 754 376� 905 245 376 226 550 727�\u0012 680 628� 469 589\u0012 403 63639 730 727 245�O 727 376 117 169 15 905 325 695 302 658 302)�� 226 727 628� 466� 550 469 325 494 355. 73041} 658 695 600�. 811 391 169� 452 677 600 376 376 607 469 469 458 727�� 248 59 628 658 905 452� 302 226) 636 754 542 42 569w 391 658 489 355 198 754 469 722z 380� 550[ 607 226 636) 607 238 276 547 730 501 302� 226 523 386 413 680 376 452 245 452 637 228� 169 444� 246 660 489� 905 42 387 302[� 7308 636 435 299 628 730L\u0001 501[� 651 246 680� 73 169 376 628\n","==========\n","� 222 362 8d� 362\u0001\u000b 39 308\bd 237\u0001 458 308n 696 734 509} 734\u0002 289� 255 362 696 587 239\u0002N 245 362 255 35 628 444F,O�� 665\tO} 744 289 239 619} 538d\u0001� 619 431 386 582 308O� 245 431�� 734\u0012 34 718} 820} 302�47 289 612 30847 575 604\u0012 31 612 806\u0012� 58 14 205`O 489 712 248 34 31 604 734 703. 117 34 444 312( 312�\u0001\u0001 237 628 237 279� 482F( 806 34 331, 746 744 14 248 503 434) 538 58 469 695 665 237 205 339 434 466� 528. 469�} 245 386 289 744 362 469\f 469F)d 235 312 859 619 386 35 651}n 712d 362F� 255d. 308� 35F. 495 292 248 34 444\u0001} 350 743� 469 859 235 734)) 712 303 744} 248 743 431 712 524�  \u0001 332 362 575E 14 289 746 489 709 542 469} 743 303 482 248} 469 538 444 444Y 489` 525 376 376 31 538 524 3152 469 75d 205 434 239(d�} 651 362 163\n","==========\n","262\u0000 15 734 255 525 444��\u0012 248 686 347N 444 746 582 525� 255� 245 14 741 525�N 518 570� 744 15N���� 239 582 362 718F 245� 226 14 60450d 582 660 545 578 362F 239O 245 658}�) 226 578 2458 746 696� 545 36239� 469 600 552 226� 604 241� 552 312 414\u0012 38d 431 452 237 245� 388 38 744 746 295 7417� 570 312 117 65 458 525 248 248 660�7 226 142( 248 525 7� 658(43 59 458 570 701 58 727 612 503�͐� 525 350 362 604�} 239 49 38 239 245 248 660 503 245 98 420 727 503\u0001 420d 489 339F) 1 545 117\u0001 658 38 651� 469 322� 239\u0001 806 362 570) 245\u000147A 489� 712 75 570 245 49 688 570 503 552 248 403 59. 489 142\b 14� 688O 239 163 237 420� 754 827d 14 545� 660 660 444 420 658 248 578, 827 458 117 591 741 712 19 489 570 746� 312 712 469 688 117 117 560 703 489 859 390 469\f 489 19 660� 38 552 21\u0012 21\n","==========\n","� 665 458\u0000 636 66543��d} 403 237 658} 746 338 365� 746 741 228�� 302� 452 741 238 15 15 639 741 518\u0012 501 49 85939, 362 806 720�\u0012\u0012 338 691� 458 420\u0012���� 469 730 338 658 542� 466�\u0012 386� 29243\u0012�� 365\u0012� 466 302��\u0012 658 245\u0012 689 651 538 704 452 469� 376� 482� 469 704�� 469 704 569 302 542 651 15 228 15 636 466 542 42 469 156 658\u0015 302\u0015 376 518 905 704}� 660 600 73 302 542 806� 403 163 362 600 761� 15 730 730 362 420 619 550\u0015 591 237 619 660� 689 350 420 469 325���\u0012 403 434 302 302 725� 469 905�E 380\u0015 658�\u0015� 469 542� 619 487 806 235 538 658 403u 619 489��� 15��� 59 402 44 14 413� 469}� 730 550 420� 806 317 815 550 469 163 245 518 228!� 591 550 317 420 339 600 394 469 658 362 806\u0015 362 44 718 302\u0001\u001a 163} 117 905 302 754 390 390 469 538 205�} 420 15�}� 235\n","==========\n","�,� 636 734 338} 79n 741 493 587 458 741 730� 239 58 658 431\u0012 262 458 730} 63547 525 15 542 237N 58 14 458 568 458 730} 470F 380 569 545d49� 542 292 376} 237 205\f 469n 75\f 289 746 569 489E 542 421} 470 245�}} 569 520 365 470 237 525 718 552 245 292 458d43 376 620 734 38 573 303\f 38O} 542 75 688 394U 452O 292� 545}d�\u0012 542 591 730 531 704 249, 289U, 545 350 658 75 469 734 292� 744 58� 658 730 455 237 658} 620SO 431 46 501d 658 421 455� 75 303 573n 421 163 545 303 38 235 431 15 75 292 658 730 501 420 458 688 235 292\u0001� 501 501 525} 205 628 622 431� 163 394 38� 746 458� 734 237 235n 542 469 764 704 573 734\u0004 394 376 452 205XO 293 237d 292 489d 239 622 292 658i 622 469 376 545 205 469i 628 552 658} 734 469� 689 734 746 827 552 250�} 380 663 420 332 489 489 573n 332 520 600� 163 380 663 421} 73\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LdpZQXknFNY3"},"source":["## Train GPT-2\n","\n","The next cell will start the actual training of GPT-2 in aitextgen. It runs for `num_steps`, and a progress bar will appear to show training progress, current loss (the lower the better the model), and average loss (to give a sense on loss trajectory).\n","\n","The model will be saved every `save_every` steps in `trained_model` by default, and when training completes. If you mounted your Google Drive, the model will _also_ be saved there in a unique folder.\n","\n","The training might time out after 4ish hours; if you did not mount to Google Drive, make sure you end training and save the results so you don't lose them! (if this happens frequently, you may want to consider using [Colab Pro](https://colab.research.google.com/signup))\n","\n","Important parameters for `train()`:\n","\n","- **`line_by_line`**: Set this to `True` if the input text file is a single-column CSV, with one record per row. aitextgen will automatically process it optimally.\n","- **`from_cache`**: If you compressed your dataset locally (as noted in the previous section) and are using that cache file, set this to `True`.\n","- **`num_steps`**: Number of steps to train the model for.\n","- **`generate_every`**: Interval of steps to generate example text from the model; good for qualitatively validating training.\n","- **`save_every`**: Interval of steps to save the model: the model will be saved in the VM to `/trained_model`.\n","- **`save_gdrive`**: Set this to `True` to copy the model to a unique folder in your Google Drive, if you have mounted it in the earlier cells\n","- **`batch_size`**: Batch size of the model training; setting it too high will cause the GPU to go OOM. _Unlike finetuning, since you are using a small model, you can massively increase the batch size to normalize the training_.\n","- **`fp16`**: Enables half-precision training for faster/more memory-efficient training. Only works on a T4 or V100 GPU.\n","\n","Here are other important parameters for `train()` that are useful but you likely do not need to change.\n","\n","- **`learning_rate`**: Learning rate of the model training.\n"]},{"cell_type":"code","metadata":{"id":"aeXshJM-Cuaf","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["cb3adbfdbe7f4135a1810eaa2f3a81fd","599a74cc7d6841ce9c6bac43dad99d23","e604274a113c41d685bed7cc0d7f5478","f9db9772eb7842af98470415be237a14","7e029a866d4d48ec98cb966a1072da3e","d07cb0b54aef4d3a9bccc683da4ebb09","820d7612e1524eb893f255cd04da0c77","d2855022b5574829a205ac46a22254ed","43af99b592ff46c4914f4d14b3806a22","5f54933a321f45d3baa12d4fffbbe35c","49133d4ac4e649858d16975a6dc06a5f","ca33419d51954f4c8a3c82254639c9a1","243932c18af449e08765e66a3962f027","b65a5599981843cf8b7c140474361c9a","49c18fa827974adeac4f90d98647d233","28f53b0c56ec4b6cb8788c0825eca8c3"]},"executionInfo":{"status":"ok","timestamp":1623680519003,"user_tz":-120,"elapsed":24717342,"user":{"displayName":"axel arceuil","photoUrl":"","userId":"13030900473482598123"}},"outputId":"0bd75f5c-2fa9-46db-cb68-1ef799118f37"},"source":["ai.train(file_name,\n","         line_by_line=True,\n","         from_cache=False,\n","         num_steps=25646*5,\n","         generate_every=1000,\n","         save_every=1000,\n","         save_gdrive=False,\n","         learning_rate=1e-3,\n","         batch_size=4  \n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["06/14/2021 07:30:02 — INFO — aitextgen — Loading text from /content/drive/MyDrive/A5/Mémoire/notebooks/data/tokenized_training_data.csv with generation length of 350.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb3adbfdbe7f4135a1810eaa2f3a81fd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=25646.0), HTML(value='')), layout=Layout(…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["06/14/2021 07:30:03 — INFO — aitextgen.TokenDataset — Encoding 25,646 rows from /content/drive/MyDrive/A5/Mémoire/notebooks/data/tokenized_training_data.csv.\n","06/14/2021 07:30:15 — INFO — pytorch_lightning.utilities.distributed — GPU available: True, used: True\n","06/14/2021 07:30:15 — INFO — pytorch_lightning.utilities.distributed — TPU available: False, using: 0 TPU cores\n","06/14/2021 07:30:15 — INFO — pytorch_lightning.accelerators.gpu — LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43af99b592ff46c4914f4d14b3806a22","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=128230.0), HTML(value='')), layout=Layout…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\u001b[1m1,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","8 999 406 485 444 513 490 499\n","==========\n","\u001b[1m2,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","2 495 502 450 457 484 513 509 510 454 469 506 509 486 495 523 475 486 521 460 493 515 499 530 458 486 478 465 520 523 507 546 513 484 514 486 480 478 490 482 484 465 507 528 542 530 469 486 514 530 541 510 512 483 498 516 521 531 486 469 478 466 490 487 499 528 495 547 513 515 499 486 560 480 518 514 490 516 481 506 510 527 495 493 513 468 478 499 518 520 482 487 518 523 486 458 488 499 495 504 518 471 521 454 458 537 458 480 547 465 482 500 478 494 499 511 515 523 490 458 485 558 480 523 520 511 502 534 465 491 507 511 513 528 507 486 486 506 478 523 454 465 493 493 480 528 498 531 547 541 518 482 483 500 517 514 511 528 514 537 479 495 465 469 469 454 505 469 523 486 510 513 523 507 518 469 546 516 472 458 547 509 496 560 465 480 458 500 458 546 507 530 490 483 510 469 496 516 488 520 560 530 498 492 511 487 468 506 490 541 520 530 495 514 498 512 486 511 541 488 481 496 486 479 484 478 483 507 466 493 486 511 537 503 506 486 513 560 458 513 465 509 486 490 468 483 518 516 475 495 507 560 534 528 478\n","==========\n","\u001b[1m3,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","15564065867622 402 571 531 428 347 06 2804 148 142 3700\n","==========\n","\u001b[1m4,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m4,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","5 530 531 478 495 486 511 518 459 517 483 534 518 503 588 481 469 517 493 502 548 507 507 460 517 515 495 502 496 454 490 496 487 508 551 491 502 452 510 548 487 478 489 551 483 506 502 495 510 486 515 496 508 551 516 564 518 490 483 483 510 540 530 495 486 499 521 496 519 495 509 489 499 509 493 493 510 469 484 493 517 423 495 524 508 487 507 530 521 486 488 515 460 526 524 486 486 499 506 527 502 490 458 569 527 508 500 519 454 507 513 491 495 496 513 489 460 487 538 475 515 489 488 511 501 516 501 459 564 526 530 484 481 454 482 490 490 481 480 493 510 493 524 518 534 509 551 495 494 503 487 483 517 493 524 493 505 538 487 495 491 525 503 503 478 505 501 499 483 517 459 517 490 518 527 501 500 460 516 526 472 499 493 502 468 494 564 501 499 509 481 501 495 498 487 517 518 502 503 515 486 501 486 531 487 494 505 548 434 478 513 460 499 511 503 488 491 526 493 500 481 524 515 499 493 505 491 496 490 501 494 508 488 548 469 452 530 534 498 494 453 505 484 534 510 516 529 484 503 503 459 498 520 496 530\n","==========\n","\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","565 524 495 512 510 520 488 524 485 527 501 478 509 542 458 510 516 506 540 521 485 495 509 493 504 500 478 516 523 515 524 506 524 520 524 496 494 536 465 476 516 465 493 488 490 524 508 498 499 489 505 502 534 465 496 493 534 511 509 527 506 516 476 512 469 471 469 520 484 494 525 489 509 502 508 518 488 501 501 524 515 515 477 494 542 515 554 517 534 497 524 495 521 499 486 516 499 510 513 516 536 484 507 511 495 498 505 488 502 516 487 512 510 499 525 506 503 480 516 496 494 511 513 489 494 483 465 521 494 527 506 520 471 508 537 457 542 484 479 527 469 453 510 494 518 507 530 502 536 453 499 525 509 465 485 497 504 490 542 525 515 460 528 486 471 534 518 508 496 491 488 499 490 485 487 473 494 450 537 486 460 515 518 510 499 499 512 473 502 505 492 483 515 466 499 518 506 517 484 494 519 501 495 508 496 495 518 479 525 491 483 512 499 486 520 503 488 459 522 507 506 496 516 483 502 485 491 461 487 476 450 471 469 465 524 536 460 485 478 450 499 483 536 524 520 501 524 524 473 466 516 499 477 478\n","==========\n","\u001b[1m6,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m6,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","47 494 510 492 547 542 471 478 529 456 510 477 534 501 552 506 511 510 477 477 534 515 509 464 511 496 460 588 547 488 516 490 534 460 493 517 490 518 519 507 502 467 511 516 513 534 480 486 516 515 507 460 467 496 482 472 462 481 483 546 454 489 509 521 520 486 518 474 500 516 508 459 488 502 490 482 462 468 517 462 4666 529 513 462 515 515 471 520 530 509 503 488 499 466 546 478 547 499 476 500 530 502 477 507 503 488 503 486 490 507 516 462 484 468 477 528 514 500 520 572 528 488 493 496 520 462 490 460 534 488 530 528 534 484 499 484 528 502 474 454 500 458 534 520 564 495 503 482 528 482 521 502 515 517 509 458 528 516 509 482 512 532 508 499 534 525 472 485 516 471 516 503 512 497 510 489 474 462 530 500 503 460 527 496 501 477 485 496 493 474 460 528 547 546 542 501 521 480 483 502 477 473 510 508 503 488 485 488 528 481 502 454 476 469 471 532 465 499 528 510 496 503 503 528 493 502 500 472 539 482 468 454 515 473 483 500 515 515 527 465 521 519 471 534 454 518 534 475 510 499 541 520 501 546\n","==========\n","\u001b[1m7,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m7,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","43 475 486 567 484 572 518 523 517 482 485 500 466 489 466 513 512 477 487 546 530 481 506 524 465 493 521 491 524 506 490 486 489 506 511 500 491 513 508 477 495 488 516 505 469 462 514 501 521 530 493 556 550 487 508 527 499 462 481 542 487 529 450 526 500 513 469 511 558 506 483 484 466 459 490 514 446 484 540 513 514 518 448 506 488 532 490 487 499 509 484 490 513 497 556 508 489 554 483 489 518 516 514 532 536 546 483 488 496 481 479 495 506 581 490 466 516 458 466 529 502 503 484 494 536 482 495 505 516 500 515 488 501 497 545 508 487 536 532 509 503 489 528 485 460 509 488 462 521 516 489 554 474 523 462 508 526 482 532 540 520 517 524 466 511 488 516 466 487 480 550 490 516 454 505 516 500 503 523 518 484 511 518 540 502 489 488 509 489 538 517 554 493 493 536 530 556 497 511 510 474 506 482 514 497 513 507 488 507 513 511 477 551 509 554 556 556 466 497 506 521 540 489 487 485 572 483 528 510 546 512 466 539 486 509 530 462 536 486 509 500 517 495 513 488 494 474 510 479 517 497 496 516 493\n","==========\n","\u001b[1m8,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m8,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","50 515 510 480 499 466 515 508 492 500 515 488 493 499 564 490 524 488 471 510 482 507 499 503 487 5054416 434 509 516 517 486 48546 480 510 508 548 516 502 481 484 516 508 513 500 534 530 498 480 546 507 462 530 512 515 532 502 475 503 508 501 485 507 529 503 534 488 501 530 523 551 534 444 501 505 482 466 5225354525 513 512 551 493 484 499 493 494 515 499 513 484 482 477 516 484 490 486 484 511 459 502 524 524 539 490 488 524 466 522 459 501 534 501 500 500 548 503 513 499 495 460 484 534 512 524 494 466 515 524 525 482 484 538 503 511 516 509 488 516 500 513 462 490 530 525 490 493 505 473 478 465 518 523 501 503 511 485 566 490 495 500 513 473 471 473 509 509 494 524 522 500 450 513 528 481 518 503 460 488 480 524 465 480 513 513 491 505 510 462 534 505 499 560 490 465 507 500 530 498 503 516 528 492 512 474 462 486 495 468 469 503 443 513 500 499 486 454 502 493 480 509 503 485 524 508 528 506 480 475 484 499 486 528 513 503 493 490 487 503 531 527 500 490 512 494 475 443 496\n","==========\n","\u001b[1m9,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m9,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","99 564 503 475 520 510 477 483 502 488 578 486 505 499 535 524 458 503 551 525 498 527 551 486 529 452 548 571 538 458 573 510 512 435 537 490 520 459 483 458 507 483 532 493 487 462 488 551 450 531 588 483 532 495 556 506 522 477 489 538 513 495 505 537 565 488 453 548 564 520 471 548 488 528 485 459 459 512 495 459 488 489 490 466 482 459 495 485 507 496 515 512 534 513 489 486 478 513 469 532 534 507 483 505 516 482 515 482 510 450 482 489 470 446 499 459 485 503 533 493 502 458 459 539 495 449 496 459 513 513 532 540 536 564 548 497 458 537 527 517 502 527 508 510 486 496 502 486 499 507 488 538 482 488 505 520 483 524 474 534 485 507 496 516 524 502 460 516 471 513 507 494 493 480 520 518 536 488 457 494 485 487 503 528 453 482 487 512 507 485 503 528 482 548 478 551 450 483 507 522 498 459 482 495 536 507 511 497 538 488 488 509 495 530 524 460 458 493 548 492 469 493 503 531 550 458 551 454 466 507 489 435 529 528 518 539 486 524 499 485 533 505 524 489 548 515 482 512 503 486 528 490 465 489 458\n","==========\n","\u001b[1m10,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m10,000 steps reached: generating sample texts.\u001b[0m\n","==========\n"," 486 471 499 534 477 515 509 496 524 450 469 568 501 477 485 456 511 554 468 499 454 530 488 493 539 506 516 492 507 538 492 548 528 462 501 485 521 538 506 466 481 485 527 520 508 494 492 486 554 490 485 534 485 458 486 462 517 518 501 51224 564 568 464 548 515 522 469 524 486 462 546 461 509 468 514 518 539 534 505 515 538 493 461 493 493 532 472 503 484 523 532 543 547 578 551 486 542 501 522 573 496 462 496 543 568 515 518 511 500 508 517 543 479 485 525 483 523 539 522 494 464 486 472 478 473 501 519 490 468 537 539 527 464 522 468 494 494 478 496 473 494 539 522 560 532 536 514 503 503 521 471 492 499 539 480 483 500 499 464 486 507 546 511 503 465 486 459 497 517 521 501 516 540 470 486 502 464 483 486 493 502 503 532 537 534 494 497 528 502 473 450 499 513 490 494 511 524 498 495 502 512 447 524 461 454 538 492 486 503 493 497 488 505 481 537 492 547 511 470 523 482 461 457 487 483 498 497 512 490 502 502 507 477 528 513 501 454 490 516 518 516 505 478 461 532 485 521 517 551 490 490 505 550\n","==========\n","\u001b[1m11,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m11,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","5 573 548 572 486 466 490 480 490 469 510 480 513 487 548 528 515 539 528 496 536 513 480 467 513 530 510 506 498 515 524 500 556 502 476 507 524 508 510 536 548 462 486 487 536 471 482 546 478 485 488 452 500 488 539 516 471 500 558 500 496 477 536 479 486 515 494 529 496 485 492 499 521 464 536 462 511 529 481 506 500 466 515 515 462 499 462 510 522 512 4984 452 500 450 494 518 467 450 528 458 507 529 466 450 515 502 556 539 524 536 496 487 487 509 534 500 507 524 494 488 485 482 513 524 537 498 497 537 478 518 530 528 503 534 530 536 458 467 510 515 482 471 522 503 452 506 466 542 510 467 485 464 538 513 509 462 490 488 546 528 534 503 471 537 524 477 509 498 498 546 490 491 528 529 560 528 516 517 493 495 538 480 486 490 482 510 470 503 462 499 486 479 498 464 509 494 541 482 534 499 462 482 499 498 479 541 518 488 507 515 516 478 489 477 528 485 517 509 454 485 518 522 503 517 488 522 539 516 509 459 503 536 490 538 488 477 548 506 505 496 503 498 482 479 502 467 481 481 482 474 548 481 478 507\n","==========\n","\u001b[1m12,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m12,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","5061 528 507 528 454 488 465 527 507 476 485 475 486 542 503 515 490 473 498 528 477 528 499 466 572 515 490 502 505 477 476 508 471 534 507 486 506 465 538 496 513 486 477 477 521 516 528 496 515 515 530 528 502 482 523 516 468 485 534 538 515 465 485 530 494 487 488 477 468 529 508 504 517 506 511 487 490 534 490 487 530 469 482 519 507 538 511 501 471 519 542 534 495 499 473 550 527 501 468 483 513 510 534 460 498 511 554 509 532 492 534 473 500 465 507 476 501 512 496 483 489 509 515 494 503 515 511 484 469 466 488 506 516 462 525 507 487 506 477 494 524 524 530 507 471 498 498 488 527 477 538 494 508 493 462 515 501 528 486 478 497 473 534 524 489 494 542 524 485 447 509 500 488 473 520 490 486 506 528 499 492 513 490 506 500 488 471 465 499 501 483 513 493 502 515 534 509 508 511 528 493 477 506 486 513 521 499 495 458 462 499 482 506 477 456 504 509 503 528 459 476 508 485 496 528 485 484 494 507 487 465 507 486 473 488 501 550 494 454 501 466 492 478 529 497 477 511 534 476 508 447 506 477\n","==========\n","\u001b[1m13,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m13,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","399 089 574 302 504 0 429 521 531 302 473 482 660 379 455 530 535 478 517 476 466 568\n","==========\n","\u001b[1m14,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m14,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","6 499 551 507 495 482 487 493 449 505 513 513 489 487 540 494 496 532 496 505 490 486 481 510 482 450 453 496 458 505 509 511 507 546 485 449 499 487 506 509 457 466 499 478 494 483 469 510 449 498 511 511 473 518 460 489 532 517 469 484 499 515 512 511 487 494 492 477 477 468 515 502 493 507 460 517 485 489 539 492 486 509 485 482 503 477 517 507 554 493 513 4772 528 458 478 513 475 496 449 504 510 541 514 517 507 493 512 521 454 450 542 449 494 492 480 572 537 572 528 487 457 486 454 532 539 508 502 504 486 513 493 508 497 542 546 502 496 487 526 487 541 483 513 486 536 499 546 530 509 510 473 480 477 454 546 454 480 498 495 477 486 493 458 454 528 513 509 509 537 482 533 486 490 484 514 507 466 527 489 496 513 537 500 519 512 478 499 487 511 478 522 495 510 477 521 490 528 454 507 528 485 521 539 465 542 523 470 478 547 537 528 492 503 502 517 473 494 478 480 490 489 521 491 449 511 483 459 496 487 483 488 541 490 505 541 490 468 499 454 530 512 486 516 496 499 477 494 484 528 507 486 492 496 511\n","==========\n","\u001b[1m15,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m15,000 steps reached: generating sample texts.\u001b[0m\n","==========\n"," 443 503 485 511 494 505 510 510 462 505 519 510 499 538 482 462 495 532 503 469 514 482 487 494 518 499 512 499 458 512 481 515 533 497 518 538 457 486 505 482 479 510 462 490 490 485 481 473 479 481 499 469 483 489 524 469 507 482 500 532 477 496 534 513 462 462 490 501 483 497 486 468 491 534 483 508 488 487 495 470 466 519 489 484 513 473 490 515 499 502 490 488 485 507 490 450 484 511 513 486 484 516 529 494 533 484 503 512 493 516 502 499 462 501 486 513 484 537 507 522 528 486 513 487 542 490 504 538 508 510 485 469 521 524 485 460 489 485 481 530 481 515 489 546 495 502 508 462 478 480 462 505 511 490 469 513 490 494 538 483 485 521 499 497 502 481 496 488 502 470 534 450 499 481 495 458 506 466 514 497 490 519 469 490 452 512 512 548 479 455 524 470 458 459 488 523 499 503 462 493 513 489 505 484 516 502 452 548 502 521 534 519 484 467 564 493 473 463 464 502 513 511 507 505 486 546 489 484 548 538 493 478 521 490 511 468 484 523 488 469 487 496 564 554 515 482 484 534 520 483 487 511 469 462 487\n","==========\n","\u001b[1m16,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m16,000 steps reached: generating sample texts.\u001b[0m\n","==========\n"," 538 480 514 537 496 458 458 468 510 511 505 518 488 546 489 523 494 517 477 499 518 528 534 469 486 497 460 529 482 469 493 517 469 519 524 473 509 505 497 560 519 494 469 469 462 524 519 503 521 528 493 502 503 499 524 513 510 487 515 504 523 511 487 450 509 487 508 466 537 502 524 471 511 482 454 509 517 513 488 494 460 524 511 530 530 513 477 489 521 521 516 534 510 487 546 488 507 473 513 505 537 507 524 463 546 505 490 506 465 490 465 504 514 470 529 482 462 503 513 511 518 461 477 503 490 517 468 514 487 538 514 507 466 488 462 503 462 458 508 448 482 494 522 471 486 539 496 499 513 490 477 488 539 490 524 495 490 496 518 503 492 514 458 528 539 480 499 534 519 538 502 529 486 511 507 524 469 503 509 542 528 502 486 465 466 488 523 497 503 477 488 537 488 510 484 464 534 477 502 484 471 503 511 519 492 502 490 490 516 485 532 506 466 488 538 490 482 519 534 507 513 471 497 471 483 487 538 494 522 507 522 517 532 507 521 488 528 499 469 499 466 462 518 466 495 516 530 479 516 488 515 517 490 487 487\n","==========\n","\u001b[1m17,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m17,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","5133 521 469 521 521 510 535 519 550 439 530 582 536 458 479 517 484 483 469 551 510 517 565 494 510 549 496 515 516 486 490 483 521 480 498 487 439 471 470 480 535 528 417 466 564 513 539 509 477 499 490 513 517\n","==========\n","\u001b[1m18,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m18,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","6 0395 999 504 0 368 528 494 573 474 513 513 517 449 521 457 480 499 474 484 483 489 482 474 454 508 469 499 438 449 521 521 475 471 530 567 483 489 440 482 517 494 518 483 487 481 482 513 483 533 488 528 440 506 515 436 467 469 489 449 52550 536 513 534 530 496 530 502 573 510 488 458 494 503 475 506 524 511 510 462 482 519 513 446 507 440 477 512 564 507 503 571 499 465 435 571 487 530 552 515 486 520 422 474 551 508 515 461 534 484 462 482 507 567 483 468 435 499 496 508 532 524 474 521 573 522 505 520 476 475 507 533 482 499 521 435 484 512 497 507 461 499 474 525 519 550 495 512 483 503 528 474 447 468 494 452 557 497 518 512 412 454 442 480 521 496 497 515 458 528 486 456 588 513 461 486 496 494 487 484 422 500 509 507 542 483 521 475 505 507 513 536 4806 508 479 442 488 481 468 489 512 564 488 551 477 490 526 507 499 537 475 512 578 480 530 515 458 454 422 475 469 497 503 449 496 518 487 513 502 476 576 483 436 519 550 495 536 494 475 495 512 509 433 487 539 500 508 497 542 525 475\n","==========\n","\u001b[1m19,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m19,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","333544 527 657 483 506 471 482 660 523 488 494 532 566 531 402 510 520 443 622 520 528 511 466 411 367 410 480 531 410 495 436 520 391 536 468 482 570 511 513 449 510 530 495 493 551 579 483 512 438 499 542 516 505 411 487 442 570 628 509 534 465 559 496 530 517 527 499 513 579 505 483 418 571 483 491 594 520 475 549 502 520 520 573 528 457 508 513 471 483 549 450 549 5223 482 437 524 444 476 487 495 506 506 521 480 506 559 573 519 444 444 483 484 570 464 552 575 527 479 531 485 555 505 511 522471 499 521 567 594 537 537 481 448 526 517 510 519 493 567 499 484 464 522 527 444 477 480 434 549 524 547 458 531 552\n","==========\n","\u001b[1m20,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m20,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","0 499 552 571 513 547 475 530 583 479 531 402 567 517 594 530 493 488 445 521 485 430 508 457 437 536 533 507 511 485 529 511 530 513 514 506 502 502 536 479 444 481 506 479 521 530 538 515 548 493 530 506 483 488 477 558 478 506 483 480 478 513 494 508 499 504 490 495 486 503 483 533 496 486 505 509 473 487 459 482 514 480 518 499 487 515 450 496 492 518 503 492 521 504 478 499 554 506 431 528 518 516 496 499 520 513 444 467 469 465 492 504 515 444 509 495 449 487 501 480 509 507 444 469 539 502 460 468 469 504 459 513 503 481 449 510 459 477 466 469 487 521 519 475 516 513 493 500 486 465 475 516 505 514 492 444 494 536 458 485 503 506 511 502 480 502\n","==========\n","\u001b[1m21,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m21,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","\n","==========\n","\u001b[1m22,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m22,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","74345 538 483 523 511 504 467 538 508 480 519 524 505 494 480 531 519 512 530 506 569 482 529 519 510 490 529 494 528 564 520 483 482 527 505 484 435 488 485 483 494 501 518 538 458 479 556 454 510 494 529 528 499 488 537 532 486 551 478 512 458 488 526 521 500 488 560 454 467 486 495 486 510 514 480 540 458 467 458 454 494 501 450 527 486 488 542 500 479 528 475 462 494 530 547 493 548 450 513 494 458 477 510 495 523 540 499 495 528 519 509 499 469 516 560 550 476 524 482 506 557 486 487 431 499 476 433 452 507 578 448 542 510 471 479 536 505 528 487 495 457 521 509 493 507 451 499 555 511 507 464 448 475 523 521 482 521 519 536 513 499 450 564 495 506 484 523 479 509 477 521 509 471 515 518 458 510 499 481 432 525 482 548 481 487 510 512 487 506 482 520\n","==========\n","\u001b[1m23,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m23,000 steps reached: generating sample texts.\u001b[0m\n","==========\n"," 469 573 444 499 548 458 547 482 518 471 496 513 498 432 469 507 527 542 542 464 4665 458 503 460 447 518 566 502 502 482 524 473 488 411 496 504 487 477 509 488 480 499 489 487 505 526 461 487 494 511 478 502 493 523 499 509 505 477 512 484 486 494 526 492 484 547 551 487 450 511 513 528 511 490 411 542 487 507 511 496 504 477 485 488 490 503 484 540 501 507 558 534 478 488 573 496 494 526 503 496 515 532 484 480 505 450\n","==========\n","\u001b[1m24,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m24,000 steps reached: generating sample texts.\u001b[0m\n","==========\n"," 484 539 444 512 496 462 494 482 511 488 490 503 519 482 511 500 458 509 501 512 474 520 495 502 482 474 483 506 526 520 498 495 466 466 493 493 515 469 470 509 495 536 477 515 482 468 499 468 515 520 466 496 470 515 490 490 468 516 495 503 493 520 499 511 520 509 501 499 511 462 490 465 484 494 523 540 513 485 472 482 510 468 469 489 470 482 515 496 486 487 470 464 477 523 490 492 505 530 489 466 530 532 506 488 496 465 478 469 482 547 510 490 501 538 474 489 527 496 551 500 483 499 501 530 493 489 515 499 496 474 509 520 482 539 469 484 510 509 450 477 494 468 490 454 471 489 499 466 495 466 484 479 523 477 532 532 525 454 523 505 464 502 530 466 452 466 459 506 458 515 466 494 524 503 511 520 471 499 500 516 500 490 500 514 515 449 496 458 482 509 466 471 482 488 499 496 490 502 493 532 509 490 506 529 520 524 448 497 496 506 497 509 473 474 487 485 507 529 527 502 507 489 524 499 510 489 509 484 436 503 515 506 525 577 493 466 530 462 523 528 509 506 462 523 473 506 468 514 499 501 530 471 507 482 501\n","==========\n","\u001b[1m25,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m25,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","485 585 523 511 482 528 505 489 444 510 482 486 495 490 524 505 521 486 487 494 479 520 498 484 493 515 461 507 480 504 503 492 503 511 508 528 477 458 458 506 485 508 453 484 501 546 471 483 494 490 512 557 480 520 460 482 494 522 508 493 486 489 465 464 551 521 460 515 483 538 533 511 500 482 480 497 488 510 482 530 469 462 500 503 510 490 485 462 516 511 476 516 499 489 528 489 539 449 485 514 492 522 511 450 499 494 482 522 517 510 487 495 511 528 507 517 490 454 493 532 532 453 499 478 452 520 513 497 466 466 502 466 462 497 514 503 509 496 506 528 515 520 503 539 499 458 486 450 479 509 512 478 500 471 516 513 454 513 524 515 520 497 490 503 509 516 473 515 509 461 487 512 490 502 489 466 554 508 473 486 466 497 464 490 520 473 551 505 462 490 515 449 500 498 464 506 474 506 508 514 484 454 476 490 518 486 497 548 532 476 458 542 511 499 478 539 499 508 466 490 508 490 530 515 497 499 505 484 482 502 461 494 521 492 454 539 522 551 497 509 573 524 490 471 511 482 554 466 508 502 503 522 508 490\n","==========\n","\u001b[1m26,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m26,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","50787 0070 0 99913 504 521 523 381 591 630 473 525 341 329 375 529 463 478 406 512 469 570 547 598 495 550 508 502 476 594 437 505 452 424 488 623 557 506 486 502 508 512 551 486 432 560 509 548 504 490 455 474 499 495 478 526 483 559 513 398 526 478 464 509 487\n","==========\n","\u001b[1m27,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m27,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","585 477 520 511 507 528 415 576 585 550 448 460 502 528 538 593 486 536 494 529 449 518 491 527 507 499 502 456 472 515 528 492 478 606 519 492 499 599 476 499 452 509 512 523 490 542 454 486 505 466 472 490 488 519 516 509 481 450 486 491 529 495 540 544 478 411 508 484 486 511 486 512 482 480 532 546 552 487 505 512 533 468 532 450 516 460 490 448 515 511 395 486 468 532 498 494 493 471 495 490 471 489 450 511 495 480 482 529 506 459 482 484 483 496 511 508 571 506 471 483 532 508 538 493 466 542 529 542 489 530 506 499 511 513 472 479 520 513 523 506 542 529 503 486 511 488 486 505 456 459 499 493 453 460 481 505 488 440 510 478 501 471 483 482 506 486 508 546 491 506 508 499 480 499 502 538 513 477\n","==========\n","\u001b[1m28,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m28,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","5 520 499 489 534 477 536 501 462 488 477 512 518 530 503 479 488 541 485 569 488 487 508 480 493 471 486 503 548 547 488 503 501 468 450 506 510 483 558 524 494 499 452 519 501 503 474 518 529 542 528 472 513 490 529 505 577 476 471 488 507 538 493 496 486 482 503 514 486 513 500 496 508 484 506 521 482 520 538 489 468 506 519 485 581 477 520 488 486 478 553 450 487 530 529 496 476 529 521 482 474 499 499 527 489 453 482 477 518 519 476 520 485 480 464 465 566\n","==========\n","\u001b[1m29,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m29,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","4620 050 999 110 1618 571 363 612 0 08 795 485 203 856 0 7978 0 999 795 0 81 78 165 348 499 644 281 0 0 6445 50 0 596 885 9 16 167 166 999 330 854 16 282 171 317 445 0 330 0 999 750 330 999 1845 881 88 0 0 0 330 0 0 16 568 941 330 271 167 16 0 16 568 842\n","==========\n","\u001b[1m30,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m30,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","575 467 539 492 594 482 343 418 547 497 529 573 481 422 583 474 551 536 524 462 524 516 505 505 513 514 485 551 449 486 508 519 519 478 547 511 540 505 511 505 481 534 516 477 478 524 494 673 477 503 489 490 497 514 519 534 503 494 557 494 469 506 569 506 553 501 505 494 464 550 506 487 551 510 490 473 512 511 511 478 454 511 506 476 515 528 534 534 538 545 494 484 520 468 506 506 503 474 494 474 511 470 481 468 496 534 494 486 508 503 488 519 558 491 494 487 511 500 488 489 508 534 505 527 465 499 511 491 450 514 539 499 494 511 474 514 520 495\n","==========\n","\u001b[1m31,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m31,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","493 360 487 454 492 514 536 476 439 456 533 668 513 343 418 560 594 427 636 385 576 423 465 513 359 415 517 475 512 443 559 571 481 475 507 478 503 549 403 556 428 417 560 564 538 513 425 563 409 453 497 417 426 458 588 467 427 557 546 516 495 418 546 385 446 456 376 543 460 395 665 492 518 409 528 755 592 569 467 784 432 576 384 427 508 509 694 438 427 365 406 210 663 249 607 662 310 452 480 434 432 613 479 610 521 529 447 539 459 480 416 634 649 526 446 267 352 505 635 630 478 649 340 498 467 471 544 490 477 556 433 465 422 633 549 443 560 349 571\n","==========\n","\u001b[1m32,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m32,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","6 478 528 386 634 505 468 466 440 472 487 505 439 447 542 549 446 528 514 583 440 391 422 460 638 519 465 422 414 487 587 437 464 316 457 514 492 433 549 487 538 350 640 588 595 478 490 531 596 614 450 559 525 516 361 454 531 535 441 515 647 485 679 649 519 583 479 563 585 603 523 519 478 447 435 520 532 609 467 503 447 517 435 552 555 493 499 607 492 542 533 531 460 533 527 527 370 391 686 489 440 489 513 504 516 446 595 523 418 520 448 499 365 440 489 564 480 529 477 642 518 603 496 639 488 552 576 715 592 493 511 561 494 526 529 793 588 472 457 448 545 449 519 533 531 631 423 470 494 533 578 482 496 480 456 391 520 448 479 505 546 515 469 422 448 422 646 600 487 546 640 564 358 448 479 531 469 517 511 405 600 489 500 484 568 436 508 677 438 510 506 473 590 558 498 464 513 465 431 465 431 486 587 458 588 525 508 525 428 466 508 524 449 524 511 516 509 532 499 530 477 448 552 469 465 431 561 420 406 617 498 459 551\n","==========\n","\u001b[1m33,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m33,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","444 490 408 499 483 460 403 455 446 486 557 612 418 486 468 485 494 498 499 485 494 461 496 571 571 506 476 496 477 642 494 461 496 477 517 478 584 546 499 510 463 452 496 502 496 502 482 514 520 496 502 496 502 496 502 496 502 496 502 482 431 469 575 496 448 513 542 560 521 460 533 531 464 535 456 484 407 539 548 521 571 523 452 509 535 570 521 571 523 499 394 482 537 552 490 498 513 542 488 572 463 524 572 463 524 572 463 524 572 463 591 518 555 486 515 478 489 530 528 522 532 543 545 528 578 499\n","==========\n","\u001b[1m34,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m34,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","53 528 441 446 519 461 501 504 488 392 572 488 526 417 478 500 448 584 398 497 535 486 530 526 531 533 518 324 703 525 451 556 499 466 565 446 216 564 528 478 507 492 449 446 588 433 354 498 578 446 588 563 575 446 689 389 373 518 469 475 449 556 483 491 235 720 536 672 593 542 556 571 483 491\n","==========\n","\u001b[1m35,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m35,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","560 444 472 510 465 431 562 511 525 511 450 644 463 428 501 530 469 603 527 493 546 471 421 470 531 533 450 552 511 450 552 580 548 521 442 500 595 680 537 453 288 442 500 595 680 537 546 509 495 525 602 506 435 659 442 500 595 680 537 546 509 495 525 602 506 435 492 530 301 508 536 528 435 552 449 568 510 427 510 465 581 524 548 457 516 536 476 568 510 465 555 562 547 546 284 453 419 522 472\n","==========\n","\u001b[1m36,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m36,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","431 522 518 436 518 480 378 553 503 457 507 480 478 480 546 549 440 570 566 457 436 456 392 468 494 505 300 417 427 444 690 462 369 599 349 424 532 450 348 384 546 253 445 593 443 417 499 364\n","==========\n","\u001b[1m37,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m37,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","4444 424 468 570 530 580 450 438 565 433 381 506 624 490 450 401 388 379 492 479 508 422 453 572 658 500 439 570 517 568 313 487 523 619 530 506 607 530 506 607 498 532 517 542 577 629 502 456 465 422 411\n","==========\n","\u001b[1m38,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m38,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","6115 526 518 565 392 617 548 480 508 427 643 539 476 503 561 349 492 428 551 496 517 580 389 589 434 477 411 437 536 316 539 460 432 576 422 462 464 421\n","==========\n","\u001b[1m39,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m39,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","3612 488 394 276 326 278 468 502 643 437 717 342 413 586 603 536 435 360 597 521 512 342 572 452 642 514 566 537 496 580 534 608 488 571 321 360 419 441 544 312 501 668 527 354 600 660 389 322 477 545 463 389 487 548 442 447 382 629 210 513 354 481 563 464 436 513\n","==========\n","\u001b[1m40,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m40,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","529 513 546 524 446 518 619 476 573 510 553 557 515 506 466 459 446 599 461 626 469 480 599 461 626 517 579 501 517 579 532 469 574 477 592\n","==========\n","\u001b[1m41,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m41,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","488 520 313 553 503 485 525 505 474 504 510 467 505 510 496 474 504 521 496 536 404 437 490 463 488 480 531 460 496 536 511 583 448 528 639 466 504 569 535 513 481 438 511\n","==========\n","\u001b[1m42,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m42,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","4595 556 563 501 628 432 423 447 522 510 540 448 467 462 443 549 486 546 547 477 537 565 561 390 513 515 542 471 436 506 495 544 399 611 486 497 589 493 465 503 529 454 534 441 463 470 550 519 477 437 547 384 371 502 416 497 384 739 544 417 490 509 531 537 611 494 532 436 362 488 572 441 523 522 573 427 639 286 526 559 532 486 515 499 447 522 509 486 438 433 464 461 414 539 590 552 495 489 520 518 476 528 481 520 504 546 476 444 485 504 474 494 529 517 464 404 499 527 477 417 530 487 556 502 513 414 361 504 744 525 513 449 439 490 433 450 506 489 621 491 474 442 556 482 502 514 545 435 462 587 500 454 585 576 570\n","==========\n","\u001b[1m43,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m43,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","44455 607 371 503 276 557 379 373 296 651 370 548 835 407 645 491 485 497 409 589 601 623 596 450 342 407 725 462 517 537 430 668 529 492 507 642 506 529 663 498 456 577 456 662 449 554 593 521 511 365 540 407 587 415 637 509 417 385 491 642 423 636 560 417 546 380 338 384 600 585 310 529 482 363 635 594 459 369 329 528 585 579 368 395 555 483 583 242 536 508 462 553 446 643 518 386 528 613 432 443 529 350 593 588 519 615 417 408 429 435 297 562 301 544 472 418 432 401 538 325 534 564 275 477 475 715 481 391 342 480 443 679 664 346 700 372 582 519 602 646 530 581 462 328 475 465 565 599 540 632 571 524 453 497 392 454 554 484 472 583 638 483 656 519 346 473 396 631 662 587 590 446 475 499 634 529 445 585 385 550 420 447 506 521 415 553 457 612 358 427 445 513 434 461 435 467 451 521 636 592 457 703 518 670 410 396 461 455 583 440 513 390 538 611 303 543 275 479 581 331 628 462 606 478 409 579 577 615 467 419 500 499 565 439 570 458 565 494 531 446\n","==========\n","\u001b[1m44,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m44,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","574 518 515 499 396 497 628 521 417 458 588 502 384 270 524 502 702 474 519 729 566 451 384 557 611 457 576 467 580 482 514 360 535 444 435 444 543 564 507 447 447 488 630 447 529 462 444 271 492 444 271 430 487 500 439 570 458 565 494 531 446 605 534 434 515 499 474 575 367 430 576 557 405 547 522 595 546 455 513 444 472 538 560 476 525 488 514 565 541 483 499 500 460 444 450 426 457 478 487 536 505 517 615 535 410 559 511 536 571 554 463 476 528 409 515 499 550 477 465 397 449 541 547 368 495 560 454 426 441 450 523 418 673 487 524 374 566 548 307 618 446 489 401 598 429 323 692 559 456 483 473 588 557 587 497 486 538 483 498 582 529 513 517 439 486 468 609 478 533 392 440 595 625 507 559 297 397 486 436 504 475 376 540 612 480 517 553 528 299 532 527 426 411 608 235 308 494 379 466 273 571 529 471 231 559 441 520 361 707 439 463 648 384 176 550 364 528 571 474 724 559 326 433 95 460 474 492 570 625 385 361 576 283 519 527 368 628 570 705 318 347 613 640 384 522 558 603 482 302 710 503 162\n","==========\n","\u001b[1m45,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m45,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","509 458 522 544 378 559 617 389 534 534 590 555 427 365 390 522 589 532 565 361 589 549 505 511 621 475 574 475 481 608 563 564 458 514 661 496 480 489 422 559 549 557 547 458 403 704 574 479 444 581 439 456 550 472 558 617 539 503 623 526 491 424 566 488 539 620 556 438 531 535 471 433 516 570 576 418 542 542 598 614 441 489 477 463 546 363 374 268 283 574 548 576 526 390 512 559 532 581 521 463 410 304 551 490 174 625 474 439 578 448 597 609 433 548 365 516 554 561 593 658 532 438 660 514 527 548 373 575 472 424 444 515 516 556 495 562 516 367 353 408 545 402 593 512 595 576 492 510 632 533 456 354 523 360 435 552 580 462 647 286 585 613 457 476 612 447 366 572 539 536 571 453 543 530 441 445 373 579 507 244 318 576 456 445 321 568 435 606 471 202 508 372 525 372 414 545 416 677 561 643 437 596 576 415 517 475\n","==========\n","\u001b[1m46,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m46,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","415 546 433 487 557 358 447 472 488 536 558 532 515 465 478 431 480 486 447 471 632 544 547 411 379 418 449 532 538 512 422 482 454 436 494 463 531 482 450 460 533 479 548 469 583 456 502 452 534 523 391 499 507 585 348 431 469 430 562 318 579 572 495 560 453 560 501 528 545 434 591 458 532 538 393 458 447 565 536 462 538 511 581 358 621 626 492 480 531 541 542 557 452 519 438 469 509 413 617 536 490 526 507 524 475 482 437 543 453 529 406 508 516 471 512 489 543 447 508 484 436 477 497 467 488 537 454 553 540 513 553 517 486 534 505 470 406 471 541 487 483 507 491 438 507 504 513 537 494 574 510 509 631 548 581 459 434 522 403 501 525 459 488 526 614 525 428 492 481 620 550 514 609 464 621 523 511 456 605 511 425 512 577 494 438 487 484 518 424 524 467 584 464 482 481 452 488 491 524 462 490 496 474 565 497 476 495 416 636 561 506 543 488 505 539 483 439 449 424 442 410 530 550 436 483 476 448 595 578 459 648 446 598 599 449 531 678 421\n","==========\n","\u001b[1m47,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m47,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","547 499 476 521 581 408 434 522 510 586 497 468 527 471 614 610 490 495 481 533 488 647 522 533 506 493 546 468 498 545 482 486 375 542 369 598 431 498 556 633 489 430 563 331 549 390 379 356 513 601 476 490 603 519 624 449 587 515 454 462 511 537 522 627 538 545 565 469 506 477 638 499 618 531 469 569 500 533 614 442 454 399 551 498 367 605 552 546 463 537 469 568 582 506 365 578 508 564 599 496 536 528 476 555 486 496 536 528 476 555 486 520 488 503 464 404 619 562 522 528 476 462 498 540 573 563 466 557 509 626 503 464 577 542 456 435 480 301 571 465 513 546 552 410 420 628 365 519 400 342 423 449 511 573 454 619 564 592 429 458 606 507 504 521 458 551 498 573 488 520 482 423 403 344 693 409 563 628 402 530 501 560 673 464 515 400 564 528 427 545 511 438 511 564 415 563 565 506 390 618 480 535 523 544 572 571 513 563 451 593 544 589 239 377 612 338 392 579 468 639 491 538 445 573 449 580 388 449 556 442 291 435 567 624\n","==========\n","\u001b[1m48,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m48,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","36220 512 636 435 486 479 548 342 457 541 337 304 480 578 380 649 405 251 332 347 546 643 433 688 412 541 567 432 554 542 551 676 512 420 581 555 439 198 477 473 401 552 501 624 345 528 328 594 589 427 754 518 430 701 473 480 488 512 523 370 562 380 427 780 600 332 392 579\n","==========\n","\u001b[1m49,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m49,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","515 499 565 671 492 434 557 511 637 418 542 557 511 405 600 400 531 541 570 369 461 425 510 461 425 410 455 592 697 531 485 610 401 523 523 507 521 474 624 444 515 474 477 386 561 467 420 371 533 493 471 509 479 576 456 441 463 459 512 580 357 485 455 360 490 471 580 482 388 571 523 464 516 517 600 410 537 571 444 587 524 479 550 560 586 615 506 514 486 505 452 538 529 513 542 471 518 364 538 603 385 486 557 515 513 552 498 512 651 547 647 502 521 501 462 448 467 313 406 520 513 510 365 442 538 571 519 484 541 521 552 335 559 593 489 575 489 530 488 418 564 515 573 552 560 501 540 444 505 519 505 358 473 550 501 490 519 558 504 569 455 479 399 401 550 508 434 540 581 483 460 485 488 394 519 523 477 673 495 494 468 494 379 418 529 505 511 583 539 554 452 479 583 533 503 561 489 452 523 496 505 435 515 595 443 497 490 661 534 475 482 558 450 553 529 488 391 442 519 539 473 463 456 499 533 532 446 444 482 553 559 565 555 452 452 503 524 470 496 480 525 507 509 491\n","==========\n","\u001b[1m50,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m50,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","513 519 423 467 584 649 405 478 507 492 449 613 494 554 489 463 547 697 518 453 500 582 489 462 479 269 644 412 396 573 459 520 554 621 491 547 585 462 514 548 420 534 598 536 590 468 590 434 482 562 559 597 458 560 469 518 580 627 515 474 480 494 534 545 522 494 562 544 457 632 602 624 444 671 626 517 471 371 410 282 383 841 618 566 360 363 612 442 483 571 491 608 457 534 669 605 546 688 496 431 549 660 373 511 171 547 737 391 376 566 464 183 469 434 735 589 232 233 471 554 517 610 597 578 470 654 500 286 371 505 592 609 582 607 261 428 687 514 390 525 571 256 206 553 648 481 319 414 485 495 638 558 290 550 496 484 739 429 504 400 449 332 613 406 550 485 559 590 474 572 553 673 587 666 476 476 476 476 599 385 569 431 458 440 581 295 496 663 435 550 566 434 423 413 587 512 531 325 569 541 618 481 606 588 503 528 510 494 459 496 691 422 370 400 523 439 561 331 495 442 541 540 447 538 483 664 495 377 539 395 695 485 397 442 588 351 396 398 505 532 415 587 532 405 489 359 551 449 591 517 591\n","==========\n","\u001b[1m51,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m51,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","64 487 563 632 484 632 596 530 577 523 534 665 329 513 637 588 521 462 369 599 612 599 498 672 702 331 537 489 550 403 413 475 544 497 454 376 721 263 660 394 508 330 530 332 522 534 461 415 690 511 525 442 413 620 440 541 254 433 564 501 493 424 539 458 462 558 527 460 617 468 325 452 534 539 490 554 421 516 488 357 435 441 532 614 598 514 540 481 521 454 422 509 476 468 658 651 500 333 478 491 487 592 493 507 507 524 435 467 463 588 410 450 460 529 401 505 406 519 485 481 524 535 452 466 590 447 553 460 550 470 547 436 523 573 599 524 538 460 488 335 517 527 452 516 502 466 459 514 520 488 614 350 495 423 480 470 626 575 572 365 489 472 444 474 483 475 570 551 511 599 429 545 469 474 447 579 511 574 477 591 538 503 603 501 522 518 436 514 451 601 535 537 417 512 449 433 484 461 547 766 563 511 518 610 619 476 511 462 443 549 561 494 439 520 559 495 489 483 553 689 560 552 478 547 483 452 582 594 591 603 612 443 604 585 519 594 554 393 499 625 670 600 400 329 538 809 419 421 382 609 752\n","==========\n","\u001b[1m52,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m52,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","542 541 487 483 507 491 438 507 545 518 567 403 644 525 644 464 578 478 486 519 644 531 476 495 554 515 433 538 481 604 520 428 498 503 417 548 529 499 438 540 644 512 487 647 502 521 501 462 448 467 313 406 520 513 510 365 442 538 571 519 484 541 521 552 335 559 593 489 575 489 530 488 418 564 515 573 552 560 501 540 444 505 519 505 358 473 550 501 490 519 558 504 569 455 479 399 401 550 508 434 540 581 483 460 485 488 394 519 523 477 673 495 494 468 494 379 418 529 505 511 583 539 554 452 479 583 533 503 561 489 452 523 496 505 435 515 595 443 497 490 661 534 475 482 558 450 553 529 488 391 442 519 539 473 463 456 499 533 532 446 444 482 553 559 565 555 452 452 503 524 470 496 480 525 507 509 491 545 431 576 489 515 505 553 488 406 402 498 450 504 494 484 508 487 463 466 467 544 474 462 497 490 507 511 482 572 483 432 429 513 517 478 524 479 554 536 478 489 512 532 490 521 551 487 464 450 469 522 510 540 448 499 514 436 455 499 510 485 425 494 506 454 504 469 483 488 546 492 434\n","==========\n","\u001b[1m53,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m53,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","498 514 527 488 375 480 467 484 583 546 492 675 470 496 502 513 579 436 505 470 457 605 511 518 546 453 577 423 514 648 715 577 476 425 591 446 548 583 654 479 488 443 564 502 595 454 362 542 325 492 544 523 598 605 622 323 461 411 433 538 513 515 364 457 615 558 534 591 487 375 511 512 597 466 402 450 599 388 635 460 551 604 458 374 479 506 482 468 502 442 540 556 564 507 447 510 557 500 495 449 405 419 513 436 414 512 432 402 465 516 463 427 411 515 576 564 455 360 492 464 426 542 472 416 507 509 375 363 691 522 517 493 551 584 516 491 459 471 580 164 537 570 406 483 570 560 576 427 368 596 523 470 546 490 541 607 477 473 424 478 530 550 403 499 497 628 423 492 571 381 506 577 457 458 413 460 487 590 494 380 283 534 377 594 485 577 635 573 467 502 601 567 529 507 447 407 502 493 554 484 385 577 481 573 579 418 584 469 505 650 440 496 536 477 353 426 462 513 344 548 508 467 528 583 549 419 541 477 411 438 582 412 523 412 432 542 481 438 507 578 476\n","==========\n","\u001b[1m54,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m54,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","569 497 621 521 460 527 550 522 537 538 488 560 462 485 480 455 478 584 398 503 547 670 409 452 476 515 509 490 620 396 497 486 512 468 586 678 574 509 568 481 641 434 506 529 492 528 761 461 413 558 572 565 474 410 452 510 462 498 445 564 386 516 413 533 474 465 717 572 481 413 544 560 497 398 550 502 425 423 680 503 490 480 488 499 442 606 682 491 481 449 444 403 376 573 485 474 489 496 422 490 416 472 556 577 486 511 528 493 530 484\n","==========\n","\u001b[1m55,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m55,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","491\n","==========\n","\u001b[1m56,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m56,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","537 457 378 206 396 509 583 504 466 367 520 415 409 486 586 611 419 389 511 595 517 454 398 383 578 564 634 617 461 473 657 522 663 555 431 549 581 339 572 552 458 406 433 403 514 564 478 469 415 492 537 618 475 566 455 485 600 615 619 466 573 564 589 483 454 517 551 486 765 530 549 508 443 600 487 502 482 394 526 549 655 564 532 462 444 522 416 587 283 627 545 479 456 570 481 676 515 568 461 375 578 374 607 543 446 559 534 359 590 462 526 516 465 422 501 542 533 567 525 536 480 599 508 354 423 365 432 423 564 381 427 675 442 368 462 556 654 416 677 447 597 516 630 424 430 394 509 470 632 507 651 474 475 497 561 526 522 477 420 548 617 451 428 500 515 593 462 527 426 543 557 651 564 484 610 599 468 540 565 671 492 504 481 419 465 520 541 462 533 519 500 519 646 591 466 593 584 500 662 518 650 479 639 349 262 321 684 302 488 393 474 394 595 663 522 663 456 678 575 467 535 458 381 431 640 242 631 479 451 616 393 267 499 509 368 487 493 415 472 638 300 510 422 587 582 163 365 589 521\n","==========\n","\u001b[1m57,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m57,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","597 495 489 483 553 689 560 552 478 547 483 452 582 594 591 603 612 443 604 585 519 594 554 393 499 625 670 600 400 329 538 809 419 421 382 609 752 611 451 529 477 739 588 452 762 432 506 333 792 272 608 278 823 423 470 499 480 630 139 473 560 571 624 460 508 624 766 630 568 354 537 538 249 651 414 654 324 475 412 592 380 492 482 269 640 383 999 774 636 440 603 474 202 458 622 520 526 734 312 622 493 455 225 574 382 511 613 686 492 501 451 876 642 455 588 509 515 559 473 491 547 333 381 622 570 290 497 450 347 550 358 28 806 531 160 235 521 480 508 571 827 523 705 299 587 486 683 578 544 689 352 574 662 468 489 121 554 535 582 433 616 497 491 428 532 567 277 338 574 461 541 666 408 390 347 413 447 519 630 609 469 466 502 488 450 650 643 449 448 276 587 608 570 646 520 507 520 475 483 665 342 501 370 566 500 355 642 478 442 489 528 480 358 549 413 485 435 479 459 571 560 629 472 524 513 515 399 485 567 364 457 487 564 479 614 552 403 639 447 537 494 417 643\n","==========\n","\u001b[1m58,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m58,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","509 436 483 476 448 595 578 459 648 446 598 599 449 531 678 421 496 519 605 401 442 584 389 569 523 375 386 468 534 500 447 470 539 566 607 633 693 532 478 389 570 558 493 547 449 537 571 463 448 277 467 536 580 421 564 408 477 445 470 496 446 493 512 539 487 584 585 423 546 566 345 434 531 567 455 473 543 557 584 615 565 443 518 465 487 574 481 552 478 408 500 365 443 492 434 513 462 537 455 372 596 528 480 532 518 494 478 521 545 466 504 464 535 571 558 482 434 461 570 414 453 493 522 472 637 564 532 527 519 522 407 495 534 499 464 551 534 514 501 477 489 447 502 554 497 621 521 460 527 550 522 537 538 488 560 462 485 480 455 478 584 398 503 547 670 409 452 476 515 509 490 620 396 497 486 512 468 586 678 574 509 568 481 641 434 506 529 492 528 761 461 413 558 572 565 474 410 452 510 462 498 445 564 386 516 413 533 474 465 717 572 481 413 544 560 497 398 550 502 425 423 680 503 490 480 488 499 442 606 682 491 481 449 444 403 376 573 485 474 489 496 691\n","==========\n","\u001b[1m59,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m59,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","506 519 560 582 554 518 565 505 502 434 539 510 487 538 537 420 419 444 475 566 521 555 601 507 693 500 617 472 654 595 494 464 453 460 386 599 580 462 454 438 450 711 443 473 462 496 497 491 550 512 502 573 306 370 439 615 447 468 611 622 538 467 601 525 486 531 535 363 485 446 532 502 509 531 469 468 581 517 385 445 465 483 643 411 507 493 501 496 522 560 503 500 487 453 284 450 520 527 503 518 479 486 545 518 533 525 644 558 452 464 578 478 486 496 533 587 458 518 453 451 523 566 471 412 433 517 600 566 541 492 500 405 417 471 544 421 470 547 492 500 365 442 500 595 512 479 622 442 454 465 442 568 435 588 502 371 502 435 542 588 502 435 376 446 416 526 549 580 459 462 505 425 482 581 623\n","==========\n","\u001b[1m60,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m60,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","615 507 524 475 482 437 543 453 529 406 508 516 471 512 489 543 447 508 484 436 477 497 467 488 537 454 553 540 513 553 517 486 486 534 505 470 406 471 541 487 483 507 491 438 507 504 513 537 494 574 510 509 631 548 581 459 434 522 403 501 525 459 434 522 403 501 525 459 488 526 614 525 428 492 481 620 550 514 609 464 621 523 511 456 605 511 425 512 577 494 438 487 484 518 424 524 467 584 464 482 481 452 452 488 491 524 462 490 496 474 565 497 476 495 416 636 561 506 543 488 505 539 483 439 449 424 442 410 530 550 436 483 476 448 595 578 459 648 446 598 599 449 531 678 421 453 403 554 565 409 430 490 565 546 571 525 496 439 483 556 460 594 499 674 557 473 481 588 465 443 283 563 498 423 529 518 462 660 441 517 448 497 506 415 508 399 600 558 432 503 456 433 545 554 601 436 538 490 552 408 483 531 563 472 386 561 565 505 481 567 520 495 562 471 582 480 534 515 464 619 552 507 460 584 448 494 387 486 376 527 453 484 557 524 477 534 493 499 426 512 458 613 584 442 476 578 515\n","==========\n","\u001b[1m61,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m61,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","506 468 417 582 623 621 515 398 526 516 428 497 540 471 392 566 498 506 367 483 476 420 420 349 402 460 582 451 422 508 509 509 421 523 396 556 422 565 488 548 622 412 457 387 467 507 606 530 543 467 531 451 442 573 515 422 411 258 296 514 456 436 423 505 708 599 381 479 434 439 399 569 584 345 555 442 557 612 572 589 449 610 493 472 602 522 604 597 527 436 518 480 378 553 503 457 607 463 523 391 435 642 772 657 429 485 480 503 485 370 542 420 415 462 494 475 549 366 331 457 491 502 430 444 499 557 594 527 350 426 433 514 582 645 319 454 628 647 405 512 651 499 490 418 446 486 578 337 381 543 488 520 515 433 458 347 490 505 492 550 508 495 399 607 446 599 520 493 610 473 467 661 567 638 496 477 432 561 390 464 395 445 419 504 479 434 459 507 585 715 559 472 673 445 465 536 437 665 391 477 482 447 726 538 485 525 447 369 527 597 448 549 327 380 463 493 510 482 487 442 541 455 583 483 523 490 576 420\n","==========\n","\u001b[1m62,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m62,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","585 494 250 584 408 492 431 421 547 560 400 501 393 644 342 535 441 397 402 499 347 543 288 442 105 852 504 869 713 416 582 881 306 653 467 511 502 546 543 646 380 634 562 537 698 469 458 443 484 597 502 616 447 335 476 446 451 384 442 452 421 531 414 758 462 559 399 723 527 517 590 507 654 448 528 587 582 486 588 418 418 197 595 402 378 459 604 373 512 705 487 547 334 581 434 444 534 636 496 628 455 487 502 270 202 511 446 635 595 546 365 465 568 617 435 455 403 663 524 430 911 635 610 281 509 496 499 586 492 517 388 329 527 595 525 545 497 627 387 501 218 622 430 550 506 669 429 433 567 479 418 682 481 375 384 627 548 412 461 458 501 451 471 362 489 398 528 521 541 553 442 482 617 581 645 591 530 506 604 486 470 520 608 381 444 463 479 491 530 406 483 537 453 657 506 394 565 545 461 517 391 456 496 431 446 482 587 496 418 605 549 575 558 540 536 497 517 536 698 553 569 644 660 560 417 471 555 351 603 457 469 277 598 505 387 488 617 751 532 518 362 593 324 660 516 613 490 248\n","==========\n","\u001b[1m63,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m63,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","313 489 528 480 358 549 413 485 435 479 459 571 560 629 472 524 513 515 399 485 567 364 457 487 564 479 614 552 403 639 447 537 494 417 643 591 489 528 592 479 445 544 562 616 614 436 522 573 541 515 647 377 445 456 673 539 418 470 703 342 522 492 671 572 430 552 552 552 552 514 495 585 450 541 505 328 525 514 577 486 507 258 480 683 546 447 447 592 429 515 329 376 533 590 374 488 489 325 526 524 574 562 460 559 430 450 461 652 453 450 589 457 550 461 502 380 469 538 593 577 542 521 527 457 451 330 473 540 432 657 501 517 473 498 457 520 618 560 594 521 487 394 452 336 475 472 487 551 551 461 573 529 507 483 458 509 464 555 483 480 511 432 517 428 538 473 545 547 481 447 434 507 509 436 581 516 521 510 494 460 477 642 494 556 464 465 533 466 488 471 460 483 533 535 456 484 517 492 500 471 433 495 527 521 540 541 503 448 466 482 457 516 536 522 467 462 486 540 486 518 538 508 525 520 609 519 458 490 494 437 435 558 522 502 545 487 465 547 593 614 476 573 441 516 466 505\n","==========\n","\u001b[1m64,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m64,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","667 515 547 476 390 567 563 466 499 574 348 470 492 548 521 506 486 503 501 405 525 505 559 477 585 545 417 466 504 476 394 448 551 498 461 474 426 561 468 528 528 547 494 529 411 432 617 495 462 546 567 484 486 423 455 635 482 552 309 324 554 264 402 537 570 300 479 472 415 439 446 394 360 592 359 750 464 315 593 550 692 310 429 613 352 637 420 553 570 461 432 498 609 514 578 318 608 333 469 522 263 375 745 402 603 550 479 684 374 391 362 576 602 317 393 620 289 424 599 311 481 447 311 427 659 503 401 424 472 370 459 591 450 413 486 507 519 522 482 646 409 440 361 635 391 571 559 715 354 351 713 566 463 411 574 214 327 271 629 606 241 314 474 262 854 387 630 353 636 378 245 788 516 517 560 428 528 554 372 738 437 362 450 626 464 519 466 260 402 394 468 711 421 462 488 743 366 790 577 586 345 483 336 273 523 377 541 570 437 625 591 508 261 519 465 867 536 562 270 636 476 554 584 607 767 514 280 372 541 749 524 294 500 557 636 806 381 399 453 348 432 567 290 518 321 354 459 466 467 846 367\n","==========\n","\u001b[1m65,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m65,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","438 485 478 557 541 406 594 500 493 420 637 593 473 554 540 507 703 430 588 548 554 490 465 540 545 332 475 326 516 440 451 549 443 548 385 528 375 399 551 392 962 434 480 501 589 442 550 524 553 512 494 596 501 461 502 524 427 571 483 542 548 555 427 483 440 533 570 475 528 588 397 511 541 489 512 440 380 456 478 469 530 427 547 615 492 578 453 607 454 522 722 509 484 460 465 569 446 528 538 481 604 520 428 498 503 417 548 529 499 438 540 644 512 487 647 502 521 501 462 448 467 313 406 520 513 510 365 442 538 571 519 484 541 521 552 335 559 593 489 575 489 530 488 418 564 515 573 552 560 501 560 501 628 538 551 521 574 479 568\n","==========\n","\u001b[1m66,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m66,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","422 573 515 422 411 258 296 514 456 436 423 505 708 599 381 479 434 439 399 569 584 345 555 442 557 612 572 589 449 610 493 472 602 522 604 597 527 436 518 480 378 553 503 457 607 463 523 391 435 642 772 657 429 485 480 503 485 370 542 420 415 462 494 475 549 366 331 457 491 502 430 444 499 557 594 527 350 426 433 514 582 645 319 454 628 647 405 512 651 499 490 418 446 486 578 422 337 381 543 488 520 515 433 458 347 490 505 492 550 508 495 399 607 446 599 520 493 610 473 467 661 567 638 496 477 432 561 390 464 395 445 419\n","==========\n","\u001b[1m67,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m67,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","559 439 319 523 628 613 393 486 467 405 533 539 610 532 568 562 394 512 453 543 530 441 445 373 579 507 244 318 576 456 445 321 568 435 606 471 202 508 372 525 372 414 545 416 677 561 643 437 596 576 415 517 475 511 576 495 336 627 588 580 559 517 550 598 479 454 640 472 392 511 680 552 455 502 549 288 425 505 544 593 454 284 553 537 645 581 561 595 539 421 518 458 530 536 385 403 323 550 442 557 551 417 588 573 428 551 613 529 432 449 544 437 575 541 505 539 555 469 483 592 471 415 402 555 552 435 562 623 549 441 515 536 510 409 472 397 495 505 592 556 546 564 413 554 457 541 654 521 546 496 446 567 404 437 534 422 557 592 475 442 458 342 516 415 543 488 630 447 486 532 451 466 547 513 523 570 430 531 416 372 460 432 518 465 557 437 493 454 402 529 535 716 513 519 592 541 524 488 520 538 479 595 498 468 505 521 456 517 499 592 348 507\n","==========\n","\u001b[1m68,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m68,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","496 498 447 333 578 594 535 566 451 487 570 521 509 338 513 474 523 523 459 332 585 434 573 357 386 562 422 449 571 523 464 516 517 600 410 402 616 413 542 448 416 586 540 532 512 489 432 580 357 566 490 442 416 549 495 526 430 546 518 462 223 468 368 442 505 577 502 501 571 440 455 422 597 474 344 505 609 575 468 427 505 433 665 541 637 417 478 507 471 713 520 437 477 594 480 449 568 533 578 380 459 477 465 389 499 292 526 496 321 443 375 570 431 642 366 688 489 433 514 466 505 412 591 467 488 607 474 424 557 312 383 554 603 599 592 535 418 552 607 508 650 563 616 592 413 299 451 598 538 744 446 666 612 582 518 442 433 347 542 631 284 473 435 451 484 452 407 655 480 531 396 594 526 628 521 526 573 531 710 548 504 371 471 453 551 466 507 471 408 500 439 534 334 434 526 609 486 668 478 502 458 471 498 560 386 512 535 559 482 512 517 458 444 587 385 470 588 477 578 490 536 439 581 513 507 493 590 444 271 430 487 469 409 476 430 455 617 607 448\n","==========\n","\u001b[1m69,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m69,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","486 498 452 552 458 488 491 573 475 575 542 414 519 560 582 554 518 565 505 502 434 539 510 487 538 537 420 419 444 475 566 521 555 601 507 693 500 617 472 654 595 494 464 453 460 386 599 580 462 454 438 450 711 443 473 462 496 497 491 550 512 502 573 306 370 439 615 447 468 611 622 538 467 601 525 486 531 535 363 485 446 532 502 509 531 469 468 581 517 385 445 465 483 643 411 507 493 501 496 522 560 503 500 487 453 284 450 520 527 503 518 479 486 545 518 533 525 644 558 452 464 578 478 486 496 533 587 458 518 453 451 523 566 504 556 548 512 656 463 492 494 455 546 499 408 530 534 452 466 470 574 495 456 525 394 528 461 542 443 468 497 467 534 593 499 488 490 486 450 530 528 575 522 483 380 401 545 511 483 481 564 553 526 537 507 555 493 488 509 526 558 567 507 476 462 498 540 573 563 466 557 509 626 503 464 577 542 456 435 480 301 571 465 513 546 552 410 420 628 365 519 400 342 423 449 511 573 454 619 564 592 429 458 606 507 504 521 458 551 498 573 488 520 482 423\n","==========\n","\u001b[1m70,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m70,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","276 504 473 531 596 425 468 494 408 516 446 643 571 473 428 381 578 630 472 596 493 517 370 532 365 529 572 341 484 535 455 574 622 535 510 482 454 547 598 497 444 568 509 563 336 512 453 506 569 445 553 510 380 564 545 601 527 569 497 519 528 511 608 441 505 452 499 433 548 457 501 491 437 531 367 451 337 568 479 444 422 460 558 466 432 349 395 490 530 536 552 506 567 439 565 469 517 679 472 539 454 424 477 490 556 457 523 545 540 471 412 433 459 512 517 492 417 646 600 482 507 551 358 448 479 464 722 543 499 443 363 474 603 472 525 567 438 554 515 482 496 560 460 533 561 627 458 439 460 549 510 464 575 530 463 545 527 563 518 565 541 579 533 524 497 455 536 473 509 459 495 568 370 507 493 470 595 415 427 444 531 507 512 528 560 497 433 449 496 428 600 584 457 448 552 546 486 408 458 540 448 529 398 447 529 454 513 560 498 485 558 487 576 513 478 499 532 491 558 518 473 462 465 565 526 526 477 557 543 547 497 485 422 466 499 495 482 537 604 563 400 348\n","==========\n","\u001b[1m71,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m71,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","516 444 523 486 470 418 498 392 566 583 506 376 531 410 533 631 381 560 585 524 421 552 523 604 558 478 522 480 442 440 472 458 602 474 561 606 541 482 467 478 555 427 535 401 540 515 402 500 510 438 369 471 426 344 416 390 420 232 472 548 442 520 482 591 202 547 499 408 452 241 374 423 442 335 846 145 552 387 576 941 364 428 859 355 771 670 496 528 374 370 243 348 380 475 415 467 459 279 179 576 999 385 370 537 509 352 0 281 308 198 288 999 999 300 340 0 706 497 341 676 312 239 0 417 404 771 463 479 350 639 730 759 513 520 435 58 435 334 424 580 620 449 585 706 503 789 876 368 50 302 370 444 493 470 387 338 427 833 386 315 676 799 708 618 392 151 251 560 688 595 0 221 493 262 389 964 751 379 567 697 333 680 558 681 686 570 130 354 499 319 498 520 538 435 866 536 474 162 560 414 342 413 666 527 437 169 364 666 555 623 617 407 696 825 531 665 525 387 380 229 577 485 724 762 730 224 513 524 433 493 727 525 656 355 329 285 597 315 727 413 516 612\n","==========\n","\u001b[1m72,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m72,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","491 482 463 535 490 471 539 454 488 471 551 536 464 490 555 536 522 453 426 425 540 432 395 490 528 561 500 583 498 464 327 417 522 494 492 430 458 500 544 462 454 482 523 539 530 400 482 485 529 530 463 476 540 587 507 498 532 507 504 461 588 510 511 450 644 463 428 501 530 469 603 513 450 552 484 504 513 465 431 578 516 479 520 531 478 367 491 441 507 458 547 546 515 527 501 546 471 506 483 489 500 518 459 512 454 643 506 484 468 526 499 466 397 528 474 490 413 493 438 531 462 492 502 473 544 585 496 476 518 516 537 486 557 510 506 516 451 495 486 592 534 469 514 515 461 512 495 506 514 482 368 500 597 460 502 414 497 508 488 502 436 522 528 496 508 489 440 450 476 414 509 501 476 486 520 572 529 480 511 499 481 508 515 490 534 601 452 540 532 470 550 500 550 558 498 491 509 503 509 472 461 511 470 511 499 474 528 517 527 490 581 627 377 485 519 553 509 793 498 567 600 632 460 639 747 999 225 565 487 441 337 238 544 650 412 581 482 524 409 429 474 432 480\n","==========\n","\u001b[1m73,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m73,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","487 546 453 284 450 520 527 503 518 479 486 545 518 533 525 644 558 452 464 578 478 486 496 533 587 458 518 453 451 523 566 504 556 548 512 656 463 492 494 455 546 499 408 530 534 452 466 470 574 495 456 525 394 528 461 542 443 468 497 467 534 593 499 488 490 486 450 530 528 575 522 483 380 401 545 511 483 481 564 553 526 537 507 555 493 488 509 526 558 567 507 476 462 498 540 573 563 466 557 509 626 503 464 577 542 456 435 480 301 571 465 513 546 552 410 420 628 365 519 400 342 423 449 511 573 454 619 564 592 429 458 606 507 504 521 458 551 498 573 488 520 482 423 403 344 693 409 563 628 402 530 501 560 673 464 515 400 564 528 427 545 511 438 511 564 415 563 565 506 390 618 480 535 523 544 572 571 513 563 451 593 544 589 239 377 612 338 392 579 468 639 491 538 445 573 449 580 388 449 556 442 291 435 567 624 419 582 434 339 487 473 349 418 467 476 505 554 563 520 407 504 460 402 489 507 540 328 552 477 481 532 517 548 347 402 647 485 699 453 588 549\n","==========\n","\u001b[1m74,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m74,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","499 460 477 449 554 649 542 418 399 447 496 501 512 581 575 546 464 415 587 604 585 538 484 437 536 624 504 383 444 480 508 534 558 560 521 489 538 572 469 507 566 578 593 640 542 439 456 511 633 560 486 614 707 458 437 462 478 499 537 460 377 385 446 686 666 592 486 429 624 445 247 354 505 567 509 450 497 567 635 481 335 464 570 313 344 635 436 142 407 417 396 564 729 634 310 468 456 202 521 716 412 645 548 404 555 672 557 402 625 362 441 585 799 469 454 541 379 514 387 447 499 634 608 378 648 475 412 499 438 599 475 414 374 616 490 453 481 444 505 545 569 593 508 420 529 487 463 487 536 542 590 568 547 427 514 553 511 601 386 442 553 658 526 484 594 543 475 349 558 443 600 505 458 381 574 561 490 446 505 401 604 469 475 541 538 481 573 493 416 517 638 505 525 478 496 490 408 469 507 530 532 484 570 373 543 539 620 556 566 571 600 570 537 509 543 420 563 372 350 505 458 381 574 561 490 446 505 401 604 469 475 541 538 481 573 493 416 517 638 505 525\n","==========\n","\u001b[1m75,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m75,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","419 448 526 540 501 741 526 487 508 430 584 539 440 524 598 608 527 554 493 482 498 391 907 453 442 552 550 528 506 484 481 495 509 523 522 486 647 328 572 400 496 492 330 601 371 463 700 530 695 406 422 426 452 500 546 432 534 577 458 480 541 632 526 756 419 594 595 432 619 463 449 621 724 641 423 551 564 422 550 368 446 529 793 702 500 484 344 564 445 488 400 558 450 589 400 351 387 481 526 425 584 485 679 558 405 346 428 436 565 500 518 558 545 517 580 585 418 429 572 415 431 195 507 584 550 400 441 454 495 465 486 603 524 501 501 488 506 497 488 489 528 449 493 494 488 507 489 364 509 394 501 471 498 473 506 477 528 578 503 541 473 385 478 507 477 535 438 338 479 514 520 536 508 509 479 476 498 539 458 520 369 420 547 428 578 598 426 599 522 378 524 508 581 560 518 351 567 445 495 528 431 469 561 516 519 498 569 488 513 488 601 165 333 581 430 527 460 415 501 640 426 549 523 535 482 494 518 324 533 528 507 591 447 523 446 607 563 469 585\n","==========\n","\u001b[1m76,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m76,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","503 447 524 409 572 530 0 680 523 557 556 510 492 399 292 506 405 555 900 716 524 729 415 552 513 678 306 567 267 684 321 285 338 494 234 559 494 637 552 338 516 590 376 370 521 387 564 585 414 495 528 501 776 488 652 537 511 552 475 166 536 587 549 370 693 390 459 508 480 498 249 627 453 482 464 630 503 506 612 610 606 555 348 660 432 562 524 535 436 491 474 577 468 589 483 512 615 437 514 326 311 572 721 498 0 999 642 654 604 647 490 730 577 459 537 748 604 267 513 612 715 474 438 529 556 386 652 660 441 515 816 607 371 533 493 513 477 462 524 545 365 499 519 565 595 272 434 722 211 587 294 543 381 464 376 714 532 357 387 585 457 740 439 361 449 439 525 433 412 551 478 727 522 438 642 420 422 451 592 468 460 446 415 547 650 561 512 468 507 466 615 621 424 496 505 297 499 364 530 339 457 487 358 536 594 505 621 377 394 507 479 505 636 390 316 398 553 367 593 450 555 540 618 501 676 495 493 579 531 521 605 422 577 575 573 563 426 456 513 337 287 552 531 446 605\n","==========\n","\u001b[1m77,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m77,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","482 546 515 527 501 546 471 506 466 526 555 583 556 531 487 468 494 533 535 458 459 506 501 517 478 489 468 471 521 588 547 429 526 529 417 385 522 515 539 565 431 476 516 664 463 467 650 553 447 376 553 417 469 662 552 513 549 580 459 598 304 636 609 396 505 369 642 507 516 678 405 499 506 515 411 554 439 506 533 384 550 486 640 588 580 478 582 320 593 453 444 600 348 494 581 520 439 381 593 467 487 638 606 353 600 455 545 567 564 431 536 596 538 620 494 491 414 531 526 502 494 498 509 534 441 506 558 731 404 621 495 486 536 663 528 478 502 494 510 655 882 541 579 536 437 622 630 644 355 206 699 347 596 429 663 582 298 416 526 436 564 544 597 548 318 463 579 521 507 491 415 544 686 530 566 591 450 463 611 478 486 496 533 587 458 449\n","==========\n","\u001b[1m78,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m78,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","633 438 433 213 489 575 589 371 345 506 626 537 346 571 483 736 522 633 454 488 641 573 289 613 598 510 430 378 573 453 622 457 368 513 431 535 553 597 641 416 469 382 687 427 515 594 555 321 578 536 603 563 610 582 411 558 452 461 539 564 509 667 551 458 530 483 452 522 421 490 547 378 513 464 512 443 561 506 476 473 542 606 549 486 497 485 571 451 479 509 388 379 560 452 490 539 501 528 572 373 506 528 530 588 533 510 551 478 572 474 421 459 617 515 547 476 390 567 563 466 499 574 348 470 492 548 521 506 486 503 501 405 525 505 559 477 585 545 417 466 504 476 394 448 551 498 461 474 426 561 468 528 528 547 494 529 411 432 617 495 462 546 567 484 486 423 455 635 482 552 309 324 554 264 402 537 570 300 479 472 415 439 446 394 360 592 359 750 464 315 593 550 692 310 429 613 352 637 420 553 570 461 432 498 609 514 578 318 608 333 469 522 263 375 745 402 603 550 479 684 374 391 362 576 602 317 393 620 289 424 599 311 481 447 311 427 659 503 401 424 472\n","==========\n","\u001b[1m79,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m79,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","526 507 450 462 328 475 465 565 599 540 632 571 524 453 497 392 454 554 484 472 583 638 483 656 519 346 473 396 631 662 587 590 446 475 499 634 529 445 585 385 550 420 447 506 521 415 553 457 612 358 590 514 431 428 448 619 539 517 456 670 427 271 571 538 639 444 475 498 440 503 387 595 609 400 436 333 433 454 510\n","==========\n","\u001b[1m80,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m80,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","480 499 466 397 576 533 510 433 551 521 482 463 535 490 471 539 454 488 471 551 536 464 490 555 536 522 453 426 425 540 432 395 490 528 561 500 583 498 464 327 417 522 494 492 430 458 500 544 462 454 482 523 539 530 400 482 485 529 530 400 482 485 529 530 463 476 540 587 507 498 532 507 504 461 588 510 511 450 644 463 428 501 530 469 603 513 450 552 484 504 513 465 431 578 516 479 520 531 478 367 491 441 507 458 547 546 515 527 501 546 471 506 483 489 500 518 459 512 454 558 498 551 496\n","==========\n","\u001b[1m81,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m81,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","453 642 449 543 597 458 551 472 687 472 615 506 476 502 504 530 530 508 551 607 515 467 630 519 558 329 709 620 395 460 391 406 234 491 835 565 538 342 336 677 319 443 549 516 587 496 534 739 506 447 664 477 396 546 616 337 483 216 531 696 280 401 586 414 150 492 533 741 585 333 329 627 420 548 513 499 667 295 642 457 238 524 440 615 558 571 614 156 334 639 644 327 505 488 309 503 576 567 402 315 526 565 330 594 620 364 693 498 473 734 536 374 202 536 481 586 361 708 552 445 532 480 475 585 603 568 672 415 483 596 384 544 663 463 389 266 491 390 653 584 315 489 671 491 521 407 616 515 518 376 597 521 689 480 515 556 566 484 471 455 549 491 608 470 344 434 468 347 514 399 488 478 518 453 502 528 518 793 492 446 500 489 696 483 481 483 553 391 276 415 506 556 346 613 639 488 485 351 496 558 621 570 537 495 456 382 552 470 509 700 436 508 495 518 546 488 638 416 371 565 461 525 619 459 424 556 550 623 472 551 611 533 710 575 380 478 528 545 449 434 673 577\n","==========\n","\u001b[1m82,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m82,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","321 296 332 674 133 672 234 938 610 600 563 465 490 698 283 722 884 617 770 14 568 371 296 856 586 612 366 133 792 727 719 303 535 530 200 514 501 842 793 611 261 433 565 703 608 621 236 754 314 467 117 568 499 733 427 340 707 819 389 234 559 281 467 117 568 499 733 427 340 707 819 582 339 88 189 678 739 394 716 941 477 163 578 484 350 272 408 595 408 757 399 649 466 381 171 662 332 783 489 414 478 606 644 648 547 618 532 833 792 727 719 303 535 530 200 514 501 842 793 611 261 433 565 703 608 621 236 754 314 467 117 568 499 733 427 340 707 819 490\n","==========\n","\u001b[1m83,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m83,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","474 465 463 389 266 491 390 653 584 315 489 671 491 521 407 616 515 518 376 597 521 689 480 515 556 566 484 471 455 549 491 608 470 344 434 468 347 514 399 488 478 518 453 502 528 518 793 492 446 500 489 696 483 481 483 553 391 276 415 506 556 346 613 639 488 485 351 496 558 621 570 537 495 456 382 552 470 509 700 436 508 495 518 546 488 638 416 371 565 461 525 619 459 424 556 550 623 472 551 611 533 710 575 380 478 528 545 449 434 673 577 617 422 475 476 548 571 457 530 590 398 601 449 621 613 633 471 510 540 567 402 703 468 422 434 399 564 514 517 628 319 576 584 452 595 586 547 573 510 530 488 412 414 231 490 417 354 564 476 675 327 494 397 493 477 430 617 467 452 613 438 499 528 537 424 433 319 411 496 571 582 573 527 580 531 531 474 624 617 491 463 571 414 466 457 460 663 489 650 608 489 534 391 434 607 463 357 383 394 383 437 457 535 513 458 554 421 402 561 516 418 637 565 414 458 399 608 667 568 528 424 472 491 454 444 478 420 477\n","==========\n","\u001b[1m84,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m84,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","3378 528 578 404 485 444 518 538 596 473 495 565 580 548 473 521 499 540 544 468 471 462 466 485 450 560 539 467 459 457 503 508 525 520 503 464 547 494 589 474 516 586 466 502 489 541 518 529 503 477 464 557 484 499 523 571 492 454 433 457 485 492 501 538 502 460 474 501 542 534 524 547 547 413 474 554 490 581 532 546 489 472 637 524 465 409 430 490 416 371 431 502 737 415 471 509 450 601 461 628 576 428 565 429 356 549 487 355 554 500 512 473 508 677 510 460 629 446 519 465 409 434 484 516 386 541 631 490 508 420\n","==========\n","\u001b[1m85,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m85,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","503 504 504 504 505 505 506 506 506 507 507 508 508 508 508 508 489 538 541 549 450 532 535 519 516 475 507 490 508 525 524 448 463 489 521 479 434 451 467 420 458 506 516 510 463 524 577 460 370 568 539 478 510 538 476 519 568 530 484 466 419 383 456 507 362 454 571 550 526 599 525 443 476 507 429 498 581 574 550 525 515 485 566 874 536 530 569 434 329 548 589 568 417 635 411 377 556 403 519 407 487 464 496 625 431 425 530 470 432 516 573 481 501 471 452 655 546 379 530 599 576 569 435 541 449 483 471 483 471 483 602 541 425 447 542 570 458 568 491 533 539 514 521 427 451 508 485 464 388 503 413 531 468 514 506 413 560 535 402 462 520 498 459 520 595 582 553 481 484 583 568 436 519 421 499 458 531 480 493 385 454 494 530 526 496 484 483 455 468 578 486 381 543 472 489 513 458 510 646 582 558 477 524 410 447 487 511 483 416 397 482 497 433 500 509 494 460 477 407 463 615 476 448 559 428 472 462 559 462 555 572 471 521 366 585 457 448 422 448 469 388 558\n","==========\n","\u001b[1m86,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m86,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","469 592 541 524 488 520 538 479 595 498 468 505 521 456 517 499 592 348 507 575 545 569 607 463 523 540 510 560 511 542 491 333 646 543 500 468 385 499 513 423 481 592 571 585 424 470 352 405 502 538 512 662 571 415 432 228 461 424 222 605 489 510 613 637 382 336 634 469 529 584 423 534 591 467 533 395 476 573 507 517 632 460 527 568 457 509 544 421 556 544 377 387 606 488 484 495 523 632 498 495 571 517 513 435 496 496 537 475 545 524 487 572 562 494 536 521 481 439 572 463 507 521 529 521 469 446 466 518 542 511 517 630 534 569 511 459 542 529 500 440 434 495 561 442 415 492 564 536 577 445 288 595 513 423 503 480 518 532 338 436 438 567 299 412 554 423 531 590 273 649 527 608 283 522 457 400 310 68 722 596 386 722 539 500 404 320 720 575 437 495 521 406 473\n","==========\n","\u001b[1m87,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m87,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","700 518 462 660 441 517 448 497 506 415 508 399 600 558 432 503 456 433 545 554 601 436 514 360 490 552 408 483 531 563 472 386 561 565 505 481 567 520 495 562 471 582 480 534 515 464 619 552 507 460 584 448 494 387 486 376 527 453 484 557 524 477 534 493 499 426 512 458 613 584 442 476 578 515 478 577 525\n","==========\n","\u001b[1m88,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m88,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","575 471 494 570 259 785 529 410 605 576 511 580 566 324 520 683 474 487 538 437 446 636 423 594 598 579 535 506 590 524 515 418 598 468 600 457 483 447 395 531 580 549 519 506 537 617 559 497 731 578 519 503 657 576 484 467 439 439 223 486 769 573 585 418 415 659 379 348 436 479 562 449 543 785 561 510 653 584 486 564 583 409 405 170 490 669 341 452 579 458 36 510 479 654 633 340 173 194 609 576 639 542 582 412 696 453 328 423 636 577 686 578 584 321 391 654 650 434 545 543 78 219 614 654 376 245 492 563 422 583 517 138 571 455 582 702 474 203 75 416 568 449 270 669 228 755 511 557 516 568 675 581 668 409 476 333 169 489 696 599 338 313 615 377 383 774 226 436 648 540 465 547\n","==========\n","\u001b[1m89,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m89,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","394 535 513 458 554 421 402 561 516 418 637 565 414 458 399 608 667 568 528 424 472 491 454 444 478 420 477 656 476 505 316 567 517 420 326 407 529 478 593 448 396 502 531 511 389 528 308 392 357 605 462 488 572 406 491 315 549 380 534 546 675 378 526 446 352 650 543 370 536 387 361 502 500 505 521 592 706 592 291 542 430 506 542 609 514 334 476 469 581 572 576 554 420 726 540 465 541 494 573 559 443 381 503 438 339 513 537 500 623 499 526 348 528 641 697 626 384 491 426 492 378 460 487 404 540 379 492 500 562 429 339 484 498 547 477 355 470 523 657 658 437 374 424 506 574 596 350 403 542 616 341 562 677 509 535 376 402 587 543 306 336 369 556 493 410 596 397 532 444 563 586 424 615 505 440 393 678 430 507 420 455 631 482 420 631 540 662 580 470 448 576 456 339 453 557 447 503 505 503 465 485 593 755 546 489 571 388 507 594 363 664 446 462 509 477 717 562 476 480 443 329 510 582 369 540 401 426 498 510 513 380 509 523 449 500 618 428 498 484 521 428 477\n","==========\n","\u001b[1m90,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m90,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","319 574 459 430 614 350 495 423 480 470 626 575 572 365 489 472 444 474 483 475 570 551 511 599 429 545 469 474 447 579 511 574 477 591 538 503 603 501 522 518 436 514 451 601 535 537 417 512 449 433 484 461 547 766 563 511 518 610 619 476 511 462 443 549 561 494 439 520 559 495 489 483 553 689 560 552 478 547 483 452 582 594 591 603 612 443 604 585 519 594 554 393 499 625 670 600 400 329 538 809 419 421 382 609 752 611 451 529 477 739 588 452 762 432 506 333 792 272 608 278 823 423 470 499 480 630 139 473 560 571 624 460 508 624 766 630 568 354 537 538 249 651 414 654 324 475 412 592 380 492 482 269 640 383 999 774 636 440 603 474 202 458 622 520 526 734 312 622 493 455 225 574 382 511 613 686 492 501 451 876 642 455 588 509 515 559 473 491 547 333 381 622 570 290 497 450 347 550 358 28 806 531 160 235 521 480 508 571 827 523 705 299 587 486 683 578 544 689 352 574 662 468 489 121 554 535 582 433 616 497 491 428 532 567 277 338 574 461 541 666 408 390 347 413 447\n","==========\n","\u001b[1m91,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m91,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","498 673 487 529 398 507 501 461 461 502 509 514 452 447 463 509 503 509 472 461 511 470 511 499 474 528 517 527 490 581 627 377 485 519 553 509 793 498 567 600 632 460 639 747 999 225 565 487 441 337 238 544 650 412 581 482 524 409 429 474 432 480 397 536 762 398 550 597 572 454 367 503 481 369 406 656 627 452 484 589 272 466 661 513 548 436 536 360 462 511 568 495 445 299 491 502 449 280 437 515 477 407 462 503 581 697 498 385 536 507 537 491 435 518 612 490 531 499 393 532 446 474 512 561 382 607 475 554 481 378 586 514 404 415 451 503 464 486 502 464 602 478 479 371 469 627 509 438 514 378 482 533 419 465 566 437 505 567 435 462 446 462 415 573 499 576 439 536 664 392 524 486 484 526 572 410 518 660 521 598 438 533 500 534 358 504 473 467 587 418 407 433 497 510 513 608 438 496 385 597 469 508 531 508 627 527 541 358 505 370 393 364 538 502 493 425 570 502 473 375 470 552 567 454 408 421 501 488 376 468 579 436 494 409 486 418 475 517 601 554\n","==========\n","\u001b[1m92,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m92,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","480 482 451 715 662 453 546 461 345 373 459 594 511 633 162 482 367 550 623 512 511 525 521 406 560 452 516 502 466 459 378 572 491 436 546 551 507 443 376 442 471 491 379 530 483 513 499 446 507 478 446 689 462 295 518 478 526 530 501 575 446 668 593 542 556 571 567 473 539 483 491 477 551 545 565 503 390 607 418 360 397 782 473 491 583 374 565 590 426 495 445 531 380 465 479 419 457 329 509 450 675 465 763 541 429 483 521 475 405 568 425 438 481 663 463 433 418 525 606 370 467 416 530 489 630 511 539 511 687 449 535 563 467 443 467 543 349 408 458 446 595 452 485 597 483 495 627 493 495 360 365 370 120 999 322 505 483 515 503 657 489 760 437 710 602 529 696 476 468 419 330 521 426 459 415 387 612 359 414 574 375 485 546 452 481 417 483 400 476 543 462 592 561 444 515 536 493 589 521 560 460 530 491 326 456 567 513 450 443 406 484 449 518 518 576 441 534 609 437 408 493 520 540 499 551 522 544 378 559 507 544 470 518 565 392 365 353 338 609\n","==========\n","\u001b[1m93,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m93,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","454 412 491 465 481 388 379 519 442 343 559 364 506 500 475 502 371 427 515 577 408 548 476 398 566 641 630 540 561 427 355 513 598 403 573 493 428 385 684 450 349 411 519 566 507 316 477 408 539 519 620 433 544 464 537 409 449 556 356 569 712 509 442 480 547 531 652 496 537 594 404 511 601 351 476 609 366 638 425 464 388 527 579 588 555 599 464 490 503 512 374 436 557 541 406 413 450 498 404 399 462 524 358 517 386 513 538 386 469 567 212 432 556 626 554 498 460 437 399 494 498 543 648 515 440 688 494 556 524 417 503 557 676 528 535 476 575 384 611 395 431 605 511 518 546 331 501 637 312 387 462 532 479 366 489 426 402 544 513 592 612 471 419 521 489 606 397 509 485 359 461 585 452 532 665 492 522 440 489 540 280 458 607 526 610 459 380 420 561 478 346 533 455 566 484 583 559 571 490 568 550 518 537 527 517 593 465 459 531 596 425 468 494 408 516 446 643 571 473 428 381 578 630 472 596 493 517 370 532 365 529 572 341 484 535 455 574 622 535 510\n","==========\n","\u001b[1m94,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m94,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","428 367 430 576 557 405 547 522 595 546 455 513 444 472 538 560 476 525 488 514 565 541 483 499 500 460 444 450 426 457 478 487 536 505 517 615 535 410 559 511 536 571 554 463 476 528 409 515 499 550 477 465 397 449 541 547 368 495 560 454 426 441 450 523 418 673 487 524 374 566 548 307 618 446 489 401 598 429 323 692 559 456 483 473 588 557 587 497 486 538 483 498 582 529 513 517 439 486 468 609 478 533 392 440 595 625 507 559 297 397 486 436 504 475 376 540 612 480 517 553 528 299 532 527 426 411 608 235 308 494 379 466 273 571 529 471 231 559 441 520 361 707 439 463 648 384 176 550 364 528 571 474 724 559 326 433 95 460 474 492 570 625 385 361 576 283 519 527 368 628 570 705 318 347 613 640 384 522 558 603 482 302 710 503 162 384 384 419 406 620 561 667 596 668 370 454 620 495 579 236 435 421 557 536 400 389 573 462 532 540 701 623 441 625 623 535 441 474 654 453 567 764 431 436 495 415 503 452 443 537 565 535 578 469 508 517 459 612 488 606\n","==========\n","\u001b[1m95,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m95,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","520 515 505 459 553 510 473 486 470 494 447 378 472 465 512 600 441 470 525 486 478 514 477 484 520 575 486 493 683 456 350 433 393 502 491 506 624 490 568 528 600 487 563 632 484 632 596 530 577 523 534 665 329 513 637 588 521 462 369 599 612 599 498 672 702 331 537 489 550 403 413 475 544 497 454 376 721 263 660 394 508 330 530 332 522 534 461 415 690 511 525 442 413 620 440 541 254 433 564 501 493 424 539 458 462 558 527 460 617 468 325 452 534 539 490 554 421 516 488 357 435 441 532 614 598 514 540 481 521 454 422 509 476 468 658 651 500 333 478 491 487 592 493 507 507 524 435 467 463 588 410 450 460 529 401 505 406 519 485 481 524 535 452 466 590 447 553 460 550 470 547 436 523 573 599 524 538 460 488 335 517 527 452 516 502 466 459 514 520 488 614 350 495 423 480 470 626 575 572 365 489 472 444 474 483 475 570 551 511 599 429 545 469 474 447 579 511 574 477 591 538 503 603 501 522 518 436 514 451 601 535 537 417 512 449 433 484 461 547 766 563 511\n","==========\n","\u001b[1m96,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m96,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","409 474 449 396 572 491 498 512 344 453 545 584 542 396 469 514 469 556 469 556 469 522 494 457 476 441 496 496 431 458 494 539 510 631 515 478 606 495 438 418 509 493 433 437 418 424 407 515 597 421 480 458 476 554 516 552 476 508 525 457 547 458 479 400 399 554 665 533 548 494 416 498 485 533 420 437 485 500 420 483 422 609 512 532 427 367 530 645 443 440 459 556 463 389 222 491 462 453 575 518 497 506 460 360 539 487 498 545 590 468 536 454 645 553 416 581 408 461 478 325 603 680 614 434 585 518 469 512 675 421 595 480 606 418 415 552 379 439 439 497 494 530 553 474 456 392 517 785 721 516 680 586 539 579 582 331 587 406 465 545 518 579 541 469 425 496 455 459 475 585 484 483 556 553 538 447 517 486 409 561 446 595 478 503 529 570 653 552 486 505 484 600 800 412 385 253 477 422 484 415 506 546 524 634 511 660 449 397 446 609 436 484 458 448 446 542 524 529 409 516 537 607 489 421 496 453 492 605 583 301 513 450 445 458 509 557 491 616 499 438 507\n","==========\n","\u001b[1m97,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m97,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","517 429 537 300 539 363 607 463 634 420 428 467 506 501 436 377 399 528 685 504 520 595 663 565 332 614 521 486 625 402 624 692 532 469 455 541 483 528 562 573 606 428 466 560 597 358 669 484 407 408 417 427 437 448 465 489 514 539 548 460 374 551 518 472 540 557 611 427 527 341 436 394 558 530 508 549 429 473 486 479 471 538 603 385 432 578 599 645 472 558 379 620 454 465 318 485 379 426 455 598 442 411 558 585 502 519 394 380 531 642 545 384 640 570 369 537 522 440 536 434 450 703 513 426 427 585 509 417 457 554 494 500 509 513 386 449 495 435 504 542 600 523 593 491 360 357 420 648 493 526 531 410 526 406 494 250 517 430 337 492 710 624 539 585 533 455 455 455 455 442 646 523\n","==========\n","\u001b[1m98,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m98,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","435 523 485 397 482 573 383 299 817 306 456 521 454 241 317 764 262 902 423 310 559 521 502 595 166 754 488 394 276 326 278 468 119 715 865 351 300 733 525 504 209 0 370 127 449 999 821 513 597 432 617 211 473 726 356 433 141 755 545 383 480 265 399 453 642 654 604 647 490 730 577 459 537 748 604 267 513 612 715 474 438 529 556 386 652 660 441 515 816 607 371 533 493 513 477 462 524 545 365 499 519 565 595 272 434 722 211 587 294 543 381 464 376 714 532 357 387 585 457 740 439 361 449 439 525 433 412 551 478 727 522 438 642 420 422 451 592 468 460 446 415 547 650 561 512 468 507 466 615 621 424 496 505 297 499 364 530 339 457 487 358 536 594 505 621 377 394 507 479 505 636 390 316 398 553 367 593 450 555 540 618 501 676 495 493 579 531 521 605 422 577 575 573 563 426 456 513 337 287 552 531 446 605 456 499 459 439 521 478 596 347 391 445 565 554 494 454 510 428 745 475 596 431 487 523 498 585 533 524 432 603 597 477 484 602 575 501 383 432\n","==========\n","\u001b[1m99,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m99,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","520 488 450 489 476 451 409 393 528 511 489 616 704 469 472 520 534 536 505 497 493 480 454 379 560 584 506 378 564 442 513 594 344 403 551 406 415 485 478 557 541 406 594 500 493 420 637 593 473 554 540 507 703 430 588 548 554 490 465 540 545 332 475 326 516 440 451 549 443 548 385 528 375 399 551 392 962 434 480 501 589 442 550 524 553 512 533 481 443 443 488 647 484 355 533 441 313 468 498 464 454 399 491 441 446 442 546 543 548 396 564 483 475 497 517 494 319 576 628 573 478 442 602 445 567 547 509 327 421 393 653 393 526 462 557 436 448 640 619 418 470 418 404 564 355 547 642 603 567 479 619 548 496 644 405 561 395 623 597 437 529 548 430 510 517 466 504 468 480 475 463 519 522 607 527 589 434 590 438 583 425 436 598 509 516 535 458 472 504 444 532 494 433 480 429 415 580 445 363 523 482 471 552 576 587 524 469 433 542 637 534 482 477 395 456 548 493 550 560 488 482 514 486 468 462 485 508 442 547 532 546 413 451 419 422 416 525 499 574 424 490\n","==========\n","\u001b[1m100,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m100,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","361 426 599 524 538 579 413 436 556 494 422 555 548 506 584 423 531 487 468 597 457 554 477 386 538 537 526 529 642 457 423 504 398 459 515 477 470 510 528 403 644 517 512 590 411 500 484 454 442 468 467 435 588 416 509 536 476 568 508 479 504 526 526 499 495 485 449 452 507 344 550 526 547 551 499 525 513 499 616 429 383 518 420 495 463 502 455 527 529 472 507 556 489 523 519 530 486 500 486 414 499 523 437 418 468 532 543 545 481 450 529 519 494 480 557 499 513 453 499 453 464 513 497 482 545 518 482 474 459 488 580 601 511 453 553 564 503 528 440 468 422 514 444 615 544 615 536 425 504 508 480 392 510 492 499 419 474 493 605 489 500 480 431 537 533 433 465 423 487 519 469 520 515 337 542 577 629 502 493 478 514 473 472 465 431 482 493 511 487 470 609 439 478 494 439 417 417 560 577 510 488 525 508 444 584 501 408 582 454 530 448 449 518 438 442 511 431 573 530 531 503 492 481 537 539 523 501 497 569 574 548 483 451 527 449 469 514 523 583 498 507 431 419\n","==========\n","\u001b[1m101,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m101,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","441 446 479 452 520 448 418 539 572 447 418 363 575 650 548 437 381 648 437 521 622 421 545 505 514 396 422 652 473 636 550 549 479 414 494 512 393 494 278 458 424 463 430 572 564 466 432 444 555 580 447 438 583 425 436 598 509 516 535 458 472 504 444 532 494 433 480 429 415 580 445 363 523 482 471 552 576 587 524 469 433 542 637 534 482 477 395 456 548 493 550 560 488 482 514 486 468 462 485 508 442 547 532 546 413 451 419 422 416 525 499 574 424 490 497 365 365 560 397 502 513 566 558 548 295 595 543 401 460 453 305 420 360 607 561 654 444 429 444 548 538 441 385 407 624 406 556 589 498 488 484 432 479 486 569 534 374 355 529 606 483 665 459 505 434 587 563 548 468 507 495 469 575 482 472 538 513 530 529 647 537 541 481 492 533 551 496 396 497 503 577 531 460 478 559 582 489 610 527 466 440 339 516 480 441 429 523 559 568 540 496 513 461 503 585 549 440 570 453 403 554 565 409 430 490 565 546 571 525 496 439 483 556 460 594 499 674 557\n","==========\n","\u001b[1m102,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m102,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","560 471 502 526 520 514 506 488 467 447 427 406 385 373 412 461 510 560 596 558 507 478 470 461 453 448 468 493 517 542 561 547 528 509 491 473 460 448 436 424 432 460 484 489 490 493 505 519 533 546 547 473 385 296 272 314 357 402 430 440 449 459 470 480 490 501 514 527 539 552 564 549 507 466 424 390 406 431 456 481 507 519 517 514 512 510 503 499 512 528 583 559 532 581 521 463 410 304 551 490 174 625 474 439 578 448 597 609 433 548 365 516 554 561 593 658 532 438 660 514 527 548 373 575 472 424 444 515 516 556 495 562 516 367 353 408 545 402 593 512 595 576 492 510 632 533 456 354 523 360 435 552 580 462 647 286 585 613 457 476 612 447 366 572 539 536 571 453 543 530 441 445 373 579 507 244 318 576 456 445 321 568 435 606 471 202 508 372 525 372 414 545 416 677 561 643 437 596 576 415 517 475 511 576 495 336 627 588 580 559 517 550 598 479 454 640 472 392 511 680 552 455 502 549 288 425 505 544 593 454 284 553 537 645 581 561 595 539 421 518 458 530 536 385 403\n","==========\n","\u001b[1m103,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m103,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","530 536 385 403 434 591 530 461 439 661 496 444 495 522 558 363 395 669 527 377 542 620 369 262 536 461 444 594 690 511 431 559 374 581 491 670 434 408 614 0 582 541 515 553 480 570\n","==========\n","\u001b[1m104,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m104,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","495 562 471 582 480 534 515 464 619 552 507 460 584 448 494 387 486 376 527 453 484 557 524 477 534 493 499 426 512 458 613 584 442 476 578 515 478 577 525 512 497 488 480 395 465 557 515 483 545 540 547 420 519 510 441 483 446 530 441 590 558 504 493 505 362 459 494 369 458 360 530 593 443 465 385 459 159 683 494 604 481 363 552 468 567 487 581 555 531 481 534 478 528 446 481 513 416 505 637 519 479 524 467 542 589 500 563 390 536 516 523 496 497 482 520 466 542 617 544 489 480 486 434 481 533 491 544 515 474 461 546 336 542 378 509 583 434 588 548 540 517\n","==========\n","\u001b[1m105,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m105,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","482 503 527 609 407 507 545 612 500 494 697 524 616 456 435 539 533 521 449 633 480 435 444 466 495 591 590 687 571 421 623 579 403 586 443 444 441 575 604 457 576 496 493 483 420 509 474 536 511 385 576 437 469 548 491 549 491 734 582 550 447 452 479 469 609 486 485 625 431 465 576 593 515 453 675 561 477 481 660 396 569 632 477 542 552 386 511 395 507 551 572 436 438 553 433 533 575 431 558 492 675 565 518 349 537 469 536 504 521 702 420 417 538 350 547 548 536 551 329 600 464 399 400 414 575 490 395 588 481 416 555 542 557 594 461 440 461 486 541 526 430 494 484 597 238 464 531 492 534 502 430 496 486 496 568 509 529 670 478 537 393 513 503 631 524 599 472 423 515 568 443 497 456 441 448 523 490 473 610 431 466 544 569 535 472 527 502 505 559 537 582 518 546 453 577 432 420 454 514 648 715 577 476 425 591 446 548 583 654 479 488 443 564 502 595 454 362 542 325 492 544 523 598 605 622 323 461 411 433 538 513 515 364 457 615 558 534 591 487 375 511 512 597 466 402 450 599 388 635\n","==========\n","\u001b[1m106,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m106,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","612 504 456 503 373 394 529 579 494 532 385 569 609 538 598 385 351 525 439 661 610 618 525 650 458 528 755 624 436 645 498 652 510 580 620 368 738 584 544 510 396 601 623 461 316 546 321 674 511 621 417 322 513 592 592 425 621 637 570 214 399 371 530 291 582 420 360 603 552 657 280 281 401 495 381 332 392 624 621 688 478 368 605 421 412 757 455 322 597 331 515 457 470 519 496 646 354 637 569 502 570 400 332 306 396 545 561 644 809 484 474 663 511 547 621 576 543 511 498 380 650 648 433 299 473 506 532 571 352 443 468 524 563 530 585 398 624 596 559 418 556 433 629 616 523 514 381 476 445 381 476 445 615 509 546 444 683 610 560 447 382 607 363 538 504 549 539 565 467 573 560 597 577 421 593 487 505 400 321 699 689 494 486 485 670 701 461 457 509 495 576 135 338 423 578 292 472 368 590 632 511 528 235 467 500 600 639 528 602 551 424 650 671 458 562 457 382 296 601 479 252 470 597 589 542 424 449 347 692 565 681 482 579 416 461 349 527 319 226 554\n","==========\n","\u001b[1m107,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m107,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","399 538 460 444 443 459 430 575 431 482 486 518 594 507 506 490 470 597 549 562 423 506 500 460 479 398 482 455 388 599 545 583 562 499 516 571 535 484 434 551 586 478 403 430 414 633 536 601 504 437 549 594 430 458 399 681 410 494 319 631 522 641 440 491 536 398 731 469 450 567 388 385 523 564 504 533 346 479 342 545 552 441 309 647 416 564 472 492 642 398 562 536 506 293 529 572 547 415 509 514 391 393 595 378 533 611 570 432 556 519 549 303 411 447 488 417 566 492 473 421 524 415 439 345 510 397 424 475 566 476 427 483 297 393 528 483 546 132 249 607 635 399 584 472 534 705 326 671 302 494 481 489 672 480 418 562 515 423 527 436 513 534 264 450 530 453 340 446 216 439 320 210 685 351 567 567 754 368 694 649 540 562 356 477 402 466 477 660 672 430 346 409 340 371 448 597 614 606 529 403 501 473 629 594 538 636 710 651 471 418 641 668 294 408 517 624 694 552 534 317 254 471 537 261 431 406 538 576 488 465 847 666 413 342 817 448 528 434 439\n","==========\n","\u001b[1m108,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m108,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","558 458 506 460 560 510 482 565 610 518 464 445 314 394 434 629 572 436 394 504\n","==========\n","\u001b[1m109,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m109,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","447 395 636 473 675 611 566 571 496 425 456 509 573 561 532 477 455 618 523 542 650 503 508 530 460 404 503 505 488 488 477 407 437 483 511 543 602 588 561 540 519 500 535 570 552 507 387 444 524 546 552 534 558 581 551 520 539 565 576 572 555 491 567 555 555 585 580 540 506 511 522 494 426 395 582 733 504 470 475 451 438 513 504 498 601 683 550 511 491 457 428 444 514 565 455 398 742 691 566 443 319 301 393 487 581 630 459 540 555 472 514 561 494 418 406 416 471 373 286 445 593 443 461 521 595 657 627 554 493 524 547 453 484 533 539 520 413 402 421 511 556 327 455 619 573 493 426 438 461 466 481 546 444 339 406 504 577 497 409 421 475 626 522 408 494 592 538 410 310 436 518 188 398 666 595 487 476 510 530 443 384 564 574 543 478 452 635 514 372 452 541 460 403 370 429 462 291 375 496 526 537 521 491 460 438 421 422 404 393 440 483 475 578 416 522 627 520 555 612 626 608 473 481 388 492 640 631 411 599 352 360 294 527 502 541 670 358 615 659\n","==========\n","\u001b[1m110,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m110,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","461 570 521 509 338 513 474 523 523 459 332 585 434 573 357 386 562 422 449 571 523 464 516 517 600 410 402 616 413 542 448 416 586 540 532 512 489 432 580 357 566 490 442 416 549 495 526 430 546 518 462 223 468 368 442 505 577 502 501 571 440 455 422 597 474 344 505 609 575 468 427 505 433 665 541 637 417 478 507 471 713 520 437 477 594 480 449 568 533 578 380 459 477 465 389 499 292 526 496 321 443 502 509\n","==========\n","\u001b[1m111,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m111,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","473 499 438 579 701 525 575 623 703 441 598 403 579 446 539 408 497 528 415 682 332 455 145 540 608 728 354 732 404 552 821 384 575 535 397 362 541 639 449 385 412 616 603 512 437 491 528 380 466 565 465 375 517 493 435 394 379 480 479 478 603 700 538 460 416 449 488 482 478 478 489 469 310 427 566 510 448 520 494 462 511 560 537 583 618 505 404 495 502 493 504 520 545 572 569 536 501 457 432 413 408 406 437 502 558 556 544 549 570 573 468 388 536 528 494 505 482 281 433 610 521 439 603 454 283 335 437 567 486 405 533 642 457 458 499 540 581 578 532 485 439 438 621 385 489 581 417 396 448 506 555 584 512 520 537 520 499 495 512 532 553 556 467 453 459 492 516 469 453 459 547 611 478 498 532 465 429 627 566 471 465 484 550 557 548 509 473 493 557 612 587 534 433 534 646 608 534 419 472 538 496 424 327 539 745 587 438 624 553 447 447 490 642 541 436 571 685 480 463 491 539 579 548 502 465 485 525 613 629 618 528 528 528 528 478 502 494 510 655 882 541 579 536 437\n","==========\n","\u001b[1m112,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m112,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","554 501 490 531 533 531 412 440 391 496 555 553 652 628 487 507 438 464 588 385 517 557 537 551 567 526 608 600 496 499 590 514 431 428 448 619 539 517 456 670 427 271 571 538 639 444 475 498 440 503 387 595 609 400 436 333 433 454 473 522 589 552 458 440 617 389 534 534 590 555 427 365 390 522 589 532 565 361 589 549 505 511 621 475 574 475 481 608 563 564 458 514 661 496 480 489 422 559 549 557 547 458 403 704 574 479 444 581 439 456 550 472 558 617 539 503 623 526 491 424 566 488 539 620 556 438 531 535 471 433 516 570 576 418 542 542 598 614 441 489 477 463 546 363 374 268 283 574 548 576 526 390 512 559 532 581 521 463 410 304 551 490 174 625 474 439 578 448 597 609 433 548 365 516 554 561 593 658 532 438 660 514 527 548 373 575 472 424 444 515 516 556 495 562 516 367 353 408 545 402 593 512 595 576 492 510 632 533 456 354 523 360 435 552 580 462 647 286 585 613 457 476 612 447 366 572 539 536 571 453 543 530 441\n","==========\n","\u001b[1m113,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m113,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","537 469 491 565 560 545 402 436 611 425 417 478 512 650 566 587 482 365 564 419 520 552 503 468 352 406 358 471 449 512 544 480 531 443 397 497 532 484 618 562 540 443 353 445 553 623 553 499 600 518 386 535 525 516 450 490 531 520 379 514 533 439 335 325 490 464 576 488 460 552 527 547 405 580 366 495 387 614 552 646 558 469 477 421 536 516 571 603 624 435 555 503 343 471 475 382 516 340 336 506 346 423 470 628 680 588 404 512 446 592 459 647 642 447 473 361 508 583 499 578 510 682 441 386 510 453 643 573 488 404 466 382 333 497 548 490 587 501 431 340 488 659 682 610 458 519 536 540 536 540 536 447 495 475 493 410 599 477 525 317 427 437 536 552 563 449 563 438 453 576 422 495 387 479 495 550 380 470 548 561 399 564 632 521 484 327 441 437 456 423 382 431 602 463 490 529 379 552 515 524 519 522 560 524 447 442 651 472 490 594 568 620 457 415 640 501 590 457 510 294 515 338 407 474 435 501 453 462 540 513 546 635 607 602 497 637 415 517 608 400 614 459 362\n","==========\n","\u001b[1m114,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m114,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","464 457 483 447 395 531 580 549 519 506 537 617 559 497 731 578 519 503 657 576 484 467 439 439 223 486 769 573 585 418 415 659 379 348 436 479 562 449 543 785 561 510 653 584 486 564 583 409 405 170 490 669 341 452 579 458 36 510 479 654 633 340 173 194 609 576 639 542 582 412 696 453 328 423 636 577 686 578 584 321 391 654 650 434 545 543 78 219 614 654 376 245 492 563 422 583 517 138 571 455 582 702 474 203 75 416 568 449 270 399 270 270 486 517 779\n","==========\n","\u001b[1m115,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m115,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","476 573 498 551 503 434 467 442 532 561 467 446 596 508 543 582 515 478 532 589 414 428 579 529 462 525 516 510 459 543 565 425 564 506 555 561 556 471 557 521 517 457 471 590 516 444 549 506 398 538 430 578 505 415 481 439 584 490 560 422 449 535 423 503 489 466 542 471 518 475 524 495 570 524 478 397 408 513 425 513 510 581 538 515 452 499 586 497 468 527 471 614 610 490 495 481 533 488 647 522 533 506 493 546 468 498 545 482 486 375 542 369 598 431 498 556 633 489 430 563 331 549 390 379 356 513 601 476 490 603 519 624 449 449 587 515 454 462 511 537 522 627 538 545 565 469 506 477 638 499 618 531 469 569 500 533 614 442 454 399 551 498 367 605 552 546 463 537 469 568 582 506 365 578 508 564 599 496 536 528 476 555 486 675 497 593 411 530 411 416 427 498 673 455 504 427 486 505 483 554 590 503 561 349 376 407 555 407 478 430 547 507 475 556 538 466 462 616 404 449 480 575 491 593 488 392 481 578 545 522 470 427 591 625 505 522 527 454 483 493 573 498 551 503 434 467\n","==========\n","\u001b[1m116,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m116,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","500 308 417 471 555 351 603 457 469 277 598 505 387 488 617 751 532 518 362 593 324 660 516 613 490 248 702 479 466 423 253 291 515 505 459 555 737 676 516 724 658 660 563 802 999 705 0 867 851 402 550 638 950 958 438 794 782 190 0 726 283 371 110 706 795 220 781 640 941 261 742 402 550 807 875 293 142 366 460 595 608 498 610 575 764 406 263 542 472 304 464 429 30 425 697 622 583 458 513 494 412 553 540 559 483 385 238 357 663 350 613 856 476 897 491 417 765 565 420 479 190 378 538 381 622 571 603 378 513 534 316 532 756 476 499 533 577 675 411 539 306 561 455 615 500 772 652 626 250 605 521 573 404 527 377 448 438 494 203 419 398 344 605 523 450 709 682 637 341 308 268 771 476 428 347 503 445 439 314 610 558 796 516 512 287 404 525 424 271 445 339 403 561 310 573 193 716 398 767 431 618 269 397 244 430 348 536 299 646 333 130 559 368 953 291 789 530 271 513 550 717 683 443 495 506 581 741 404 604 469 554 495 587 315 664 518 476 552\n","==========\n","\u001b[1m117,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m117,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","3764 491 529 542 530 502 399 413 445 458 468 488 519 544 526 501 520 581 621 538 483 660 526 371 431 502 435 447 483 552 609 563 503 449 429 403 331 422 532 563 554 418 437 488 539 589 600 570 542 513 496 518 409 441 489 541 467 530 602 565 512 470 493 523 532 518 429 529 630 530 448 623 578 499 486 477 449 554 649 542 418 399 447 496 501 512 581 575 546 464 415 587 604 585 538 484 437 536 624 504 383 444 480 508 534 558 560 521 489 538 572 469 507 566 578 593 640 542 439 456 511 633 560 486 614 707 458 437 462 478 499 537 460 377 385 446 686 666 592 486 429 624 445 247 354 505 567 509 450 497 567 635 481 335 464 570 313 344 635 436 142 407 417 396 564 729 634 310 468 456 202 521 716 412 645 548 404 555 672 557 402 625 362 441 585 799 469 454 541 379 514 387 447 499 634 608 378 648 475 412 499 438 599 475 414 374 616 490 453 481 444 505 545 569 593 508 420 529 487 463 487 536 542 529 500 633 566 538 435 504 789 485 427 486 681 643 430 479 428 448\n","==========\n","\u001b[1m118,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m118,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","404 372 541 749 524 294 500 557 636 806 381 399 453 348 432 567 290 518 321 354 459 466 467 846 367 431 318 665 417 745 456 438 593 429 484 625 502 323 564 533 437 368 542 614 337 347 276 472 370 605 560 388 475 593 277 594 333 548 623 420 309 490 508 575 450 506 481 480 645 440 593 558 341 310 825 446 527 495 390 552 407 301 485 314 477 624 410 478 263 469 382 405 549 740 372 662 543 616 512 624 497 452 408 260 428 508 552 328 634 588 439 599 616 657 466 747 638 423 339 766 363 461 471 513 417 531 527 444 239 460 518 563 651 496 375 485 295 486 536 670 487 452 444 513 673 551 471 537 655 445 467 411 669 605 514 513\n","==========\n","\u001b[1m119,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m119,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","477 553 712 444 603 481 340 538 243 368 740 445 584 329 314 577 612 454 482 445 768 358 590 482 595 410 590 346 484 507 412 491 444 564 497 607 548 546 561 486 542 414 582 513 412 365 583 627 680 524 483 457 314 429 501 587 559 364 443 538 598 501 630 460 497 431 630 420 576 334 572 473 594 508 663 605 532 434 585 566 552 487 464 534 604 405 421 413 554 491 502 409 601 581 497 562 460 475 576 628 573 478 442 602 445 567 547 509 327 421 393 653 393 526 442 622 535 572 546 505 505 353 619 500 404 530 517 516 510 548 630 302 645 440 587 493 467 312 449 366 487 513 424 492 367 329 506 446 434 445 604 546 500 493 436 559 429 474 659 418 549 401 714 482 504 550 367 450 520 288 363 533 551 409 480 424 403 438 541 548 418 288 418 558 572 545 353 426 541 663 246 392 692 482 595 578 304 415 641 521 412 628 552 388 608 427 473 552 561 549 448 606 423 387 362 554 374 348 499 634 557 384 639 570 445 381 452 424 539 867 400 603 486 370 399 520 422 464 294 684 510 294 496\n","==========\n","\u001b[1m120,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m120,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","434 558 440 399 295 538 492 588 535 538 496 694 496 559 475 424 451 582 499 649 684 514 548 488 189 597 487 510 375 234 498 605 461 410 480 499 483 475 485 485 318 526 523 629 407 542 587 336 633 384 451 411 513 488 510 578 409 578 385 486 588 455 565 559 667 529 391 544 459 587 633 428 522 432 496 325 478 493 412 493 417 461 448 579 575 410 465 499 496 418 518 576 570 537 457 589 521 678 553 589 348 498 480 563 372 350 519 550 664 613 389 495 523 457 605 449 521 321 598 527 584 437 548 446 507 500 405 417 471 544 444 368 348 580 454 559 414 431 508 364 753 442 617 475 431 472 556 745 428 610 403 599 411 403 580 482 474 455 482 502 495 563 575 437 514 427 486 557 684 556 478 449 359 496 475 512 520 423 516 467 499 571 486 612 418 614 485 460 549 495 521 581 535 534 426 573 435 528 355 468 465 562 531 446 558 495 404 422 460 467 506 491 482 454 436 508 435 571 506 566 400 526 549 488 533 481 363 478 403 26 478 523 452 518 390 477 517 450 479 520\n","==========\n","\u001b[1m121,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m121,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","326 364 449 403 344 693 409 563 628 402 530 501 560 673 464 515 400 564 528 427 545 511 438 511 564 415 563 565 506 390 618 480 535 523 544 572 571 513 563 451 593 544 589 239 377 612 338 392 579 468 639 491 538 445 573 449 580 388 449 556 442 291 435 567 624 419 582 434 339 487 473 349 418 467 476 505 554 563 520 407 504 460 402 489 507 540 328 552 477 481 532 517 548 347 402 647 485 699 453 588 549 463 537 304 542 442 447 374 524 530 573 540 544 438 391 496 435 696 507 503 668 484 526 472 496 501 552 668 562 400 546 645 501 364 417 569 233 531 434 624 608 510 517 394 403 445 578 568 464 502 302 591 479 458 533 387 600 640 588 343 607 373 458 579 545 322 654 404 498 490 460 343 538 427 555 426 502 513 579 456 647 521 567 524 492 444 523 486 470 418 498 392 566 583 506 376 531 410 533 631 381 560 585 524 421 552 523 604 558 478 522 480 442 440 472 458 602 474 561 606 541 482 467 478 555 427 535 401 540 515 402 500 510 438 369 471 426 344 416 390 420 232\n","==========\n","\u001b[1m122,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m122,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","492 507 642 506 529 663 498 456 577 456 662 449 554 593 521 511 365 540 407 587 415 637 509 417 385 491 642 423 636 560 417 546 380 338 384 600 585 310 529 482 363 635 594 459 369 329 528 585 579 368 395 555 483 583 242 536 508 462 553 446 643 518 386 528 613 432 443 529 350 593 588 519 615 417 408 429 435 297 562 301 544 472 418 432 401 538 325 534 564 275 477 475 715 481 391 342 480 443 679 664 664 346 700 372 582 519 602 646 530 581 462 328 475 465 565 599 540 632 571 524 453 497 392 454 554 484 472 583 638 483 656 519 346 473 396 631 662 587 590 446 475 499 634 529 445 585 385 550 420 447 506 521 415 553 457 612 358 427 445 513 434 461 435 467 451 521 636 592 457 703 518 670 410 396 461 455 583 440 513 390 538 611 303 543 275 479 581 331 628 462 606 478 409 579 577 615 467 419 500 499 565 439 570 458 565 494 531 446 605 534 434 515 499 474 575 367 430 576 557 405 547 522 595 546 455 513 444 472 538 560 476 525 488 514 565 541 483 499 500 460 444 450 426 457 478 487 536 505 517 615 535 410 559 511\n","==========\n","\u001b[1m123,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m123,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","504 513 537 494 574 510 509 631 548 581 459 434 522 403 501 525 459 488 526 614 525 428 492 481 620 550 514 609 464 621 523 511 456 605 511 425 512 577 494 438 487 484 518 424 524 467 584 464 482 481 452 452 488 501 515 537 521 547 503 524 431 409 538 471 485 509 515 472 660 463 524 481 524 457 515 493 499 524 485 450 432 504 501 406 488 566 471 637 550 511 566 472 566 472 501\n","==========\n","\u001b[1m124,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m124,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","535 531 632 526 587 538 511 502 527 538 638 425 570 502 473 375 470 552 567 454 408 421 501 488 376 468 579 436 494 409 486 418 475 517 601 554 491 559 625 621 438 598 480 531 533 518 386 532 449 460 582 511 554 583 572 364 603 468 488 412 450 353 550 476 515 583 514 524 673 532 634 445 461 480 471 495 519 509 492 511 566 403 516 540 528 495 409 479 505 492 476 516 570 409 457 458 509 603 551 507 473 454 402 529 535 716 513 519 592 541 524 488 520 538 479 595 498 468 505 521 456 517 499 592 348 507 575 545 569 607 463 523 540 510 560 511 542 491 333 646 543 500 468 385 499 513 423 481 592 571 585 424 470 352 405 502 538 512 662 571 415 432 228 461 424 222 605 489 510 613 637 382 336 634 469 529 584 423 534 591 467 533 395 476 573 507 517 632 460 527 568 457 509 544 421 556 544 377 387 606 488 484 495 523 632 498 495 571 517 513 435 496 496 537 475 545 524 487 572 562 494 536 521 481 439 572 463 507 521 529 521 469 446 466 518 542 511 517 630 534 569\n","==========\n","\u001b[1m125,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m125,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","466 547 415 509 514 391 393 595 378 533 611 570 432 556 519 549 303 411 447 488 417 566 492 473 421 524 415 439 345 510 397 424 475 566 476 427 483 297 393 528 483 546 132 249 607 635 399 584 472 534 705 326 671 302 494 481 489 672 480 418 562 515 423 527 436 513 534 264 450 530 453 340 446 216 439 320 210 685 351 567 567 754 368 694 649 540 562 356 477 402 466 477 660 672 430 346 409 340 371 448 597 614 606 529 403 501 473 629 594 538 636 710 651 471 418 641 668 294 408 517 624 694 552 534 317 254 471 537 261 431 406 538 576 488 465 847 666 413 342 817 448 528 434 439 591 473 647 515 514 326 382 542 459 242 765 424 394 534 414 493 436 629 531 552 315 492 391 447 380 507 665 515 542 546 605 507 337 461 555 435 380 572 504 579 520 619 624 514 404 480 450 635 708 767 624 472 244 379 474 532 508 422 352 531 587 454 549 609 602 453 456 511 641 388 326 399 581 470 530 596 504 335 548 567 437 644 464 533 638 474 543 634 354 468 465 534 480 158 382 544 444 338 566 591\n","==========\n","\u001b[1m126,000 steps reached: saving model to /trained_model\u001b[0m\n","\u001b[1m126,000 steps reached: generating sample texts.\u001b[0m\n","==========\n","440 627 437 336 531 525 502 582 531 583 446 507 495 489 453 495 278 482 335 588 502 477 615 423 433 556 438 565 498 445 445 389 523 452 464 457 567 617 507 450 519 442 497 453 573 616 340 426 428 527 518 581 708 521 460 524 476 516 602 496 519 550 597 518 509 565 458 540 548 463 524 445 598 522 629 544 471 519 617 436 498 556 662 411 590 448 502 439 403 356 324 581 348 432 615 576 511 615 571 403 512 342 398 535 589 465 381 370 552 486 549 565 555 421 653 522 494 514 283 332 516 466 612 428 533 527 413 403 551 495 506 565 476 448 530 581 555 491 541 505 478 508 478 325 416 352 446 479 452 520 448 418 539 572 447 418 363 575 650 548 437 381 648 437 521 622 421 545 505 514 396 422 652 473 636 550 549 479 414 494 512 393 494 278 458 424 463 430 572 564 466 432 444 555 486 411 647 445 514 671 529 376 407 586 511 530 384 590 344 661 394 541 592 382 507 572 476 433 465 552 498 583 529 338 292 488 351 643 489 592 606 502 353 464 616 512 525 368 419 352 510 509\n","==========\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  warnings.warn(*args, **kwargs)\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n","    send_bytes(obj)\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n","    send_bytes(obj)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n","    self._send_bytes(m[offset:offset + size])\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n","    self._send(header + buf)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n","    n = write(self._handle, buf)\n","BrokenPipeError: [Errno 32] Broken pipe\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n","    self._send_bytes(m[offset:offset + size])\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n","    self._send(header + buf)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n","    n = write(self._handle, buf)\n","BrokenPipeError: [Errno 32] Broken pipe\n","06/14/2021 14:21:59 — INFO — aitextgen — Saving trained model pytorch_model.bin to /trained_model\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"qQJgV_b4bmzd"},"source":["You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."]},{"cell_type":"markdown","metadata":{"id":"pel-uBULXO2L"},"source":["\n","## Load a Trained Model\n","\n","Running the next cell will copy the `pytorch_model.bin`, `config.json`, `aitextgen_vocab.json`, and `aitextgen_merges.json` files from the specified folder in Google Drive into the Colaboratory VM. (If no `from_folder` is specified, it assumes the two files are located at the root level of your Google Drive)"]},{"cell_type":"code","metadata":{"id":"DCcx5u7sbPTD","colab":{"base_uri":"https://localhost:8080/","height":328},"executionInfo":{"status":"error","timestamp":1623680528987,"user_tz":-120,"elapsed":365,"user":{"displayName":"axel arceuil","photoUrl":"","userId":"13030900473482598123"}},"outputId":"244cb79a-e8c6-490f-e602-bace7007a166"},"source":["from_folder = None\n","\n","for file in [\"pytorch_model.bin\", \"config.json\", \"aitextgen.tokenizer.json\"]:\n","  if from_folder:\n","    copy_file_from_gdrive(file, from_folder)\n","  else:\n","    copy_file_from_gdrive(file)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-fdaea4f11e71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcopy_file_from_gdrive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcopy_file_from_gdrive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/aitextgen/colab.py\u001b[0m in \u001b[0;36mcopy_file_from_gdrive\u001b[0;34m(file_path, from_folder)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0msource_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/pytorch_model.bin'"]}]},{"cell_type":"markdown","metadata":{"id":"RTa6zf3e_9gV"},"source":["The next cell will allow you to load the retrained model + metadata necessary to generate text."]},{"cell_type":"code","metadata":{"id":"-fxL77nvAMAX","colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"status":"error","timestamp":1623680552652,"user_tz":-120,"elapsed":507,"user":{"displayName":"axel arceuil","photoUrl":"","userId":"13030900473482598123"}},"outputId":"ecda2b2f-00e6-4230-a029-42e326eaccd2"},"source":["ai = aitextgen(model_folder=\".\",\n","               tokenizer_file=\"aitextgen.tokenizer.json\",\n","               to_gpu=True)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-82782c9671ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m ai = aitextgen(model_folder=\".\",\n\u001b[1;32m      2\u001b[0m                \u001b[0mtokenizer_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"aitextgen.tokenizer.json\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                to_gpu=True)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/aitextgen/aitextgen.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, model_folder, config, vocab_file, merges_file, tokenizer_file, schema_tokens, schema_return, cache_dir, tf_gpt2, to_gpu, to_fp16, verbose, gradient_checkpointing, bos_token, eos_token, unk_token, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m             assert os.path.exists(\n\u001b[1;32m    171\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pytorch_model.bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             ), f\"There is no pytorch_model.bin in /{model_folder}.\"\n\u001b[0m\u001b[1;32m    173\u001b[0m             assert os.path.exists(\n\u001b[1;32m    174\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: There is no pytorch_model.bin in /.."]}]},{"cell_type":"markdown","metadata":{"id":"ClJwpF_ACONp"},"source":["## Generate Text From The Trained Model\n","\n","After you've trained the model or loaded a retrained model from checkpoint, you can now generate text.\n","\n","**If you just trained a model**, you'll get much faster training performance if you reload the model; the next cell will reload the model you just trained from the `trained_model` folder."]},{"cell_type":"code","metadata":{"id":"QHss16Yy0OHa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623680559899,"user_tz":-120,"elapsed":1856,"user":{"displayName":"axel arceuil","photoUrl":"","userId":"13030900473482598123"}},"outputId":"1f3b8fca-1b5b-4d8a-a0b8-2b36f6af06ed"},"source":["ai = aitextgen(model_folder=\"trained_model\",\n","               tokenizer_file=\"aitextgen.tokenizer.json\",\n","               to_gpu=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["06/14/2021 14:22:39 — INFO — aitextgen — Loading model from provided weights and config in /trained_model.\n","06/14/2021 14:22:41 — INFO — aitextgen — GPT2 loaded with 86M parameters.\n","06/14/2021 14:22:41 — INFO — aitextgen — Using a custom tokenizer.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"cZktHqhV0PYZ"},"source":["`generate()` without any parameters generates a single text from the loaded model to the console."]},{"cell_type":"code","metadata":{"id":"4RNY6RBI9LmL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623680567258,"user_tz":-120,"elapsed":4087,"user":{"displayName":"axel arceuil","photoUrl":"","userId":"13030900473482598123"}},"outputId":"35f7a603-78de-453c-9978-38a107f65062"},"source":["ai.generate()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["438 444 496 599 534 409 684 587 599 463 606 694 353 800 571 390 521 402 445 919 438 588 404 539 704 596 422 371 683 223 617 454 401 770 299 520 439 613 500 662 457 429 246 654 310 444 447 529 373 477 613 547 459 428 479 303 498 521 465 437 480 341 599 527 575 552 540 687 476 515 541 414 343 354 542 628 568 395 542 376 421 514 584 510 413 345 450 475 259 412 447 539 487 531 684 411 286 567 673 694 520 682 480 471 631 539 278 672 477 808 527 460 541 489 440 767 585 606 411 318 703 471 627 704 493 410 602 390 142 440 127 298 27 977 505 735 631 442 648 470 411 612 585 590 416 688 367 449 597 579 539 529 595 425 456 670 583 539 554 452 479 583 533 503 561 489 452 523 496 505 435 515 595 443 497 490 661 534 475 482 558 450 553 529 488 391 442 519 539 473 463 456 499 533 532 446 444 482 553 559 565 555 452 452 503 524 470 496 480 525 507 509 491 545 431 576 489 483 454 433 516 586 466 430 458 342 516 415 543 488 580 601 497 593 517 494 491 524 454\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oF4-PqF0Fl7R"},"source":["If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = ai.generate_one()`\n","\n","You can also pass in a `prompt` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n","\n","You can also generate multiple texts at a time by specifing `n`. You can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 50 for `batch_size` to avoid going OOM).\n","\n","Other optional-but-helpful parameters for `ai.generate()` and friends:\n","\n","*  **`max_length`**: Number of tokens to generate (default 256, you can generate up to 1024 tokens with GPT-2, but it will be _much_ slower)\n","* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n","* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n","* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)"]},{"cell_type":"code","metadata":{"id":"8DKMc0fiej4N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623680600083,"user_tz":-120,"elapsed":3889,"user":{"displayName":"axel arceuil","photoUrl":"","userId":"13030900473482598123"}},"outputId":"8941d216-872f-4209-b65b-a4991269cf55"},"source":["ai.generate(n=1,\n","            batch_size=5,\n","            prompt=\"123 12\",\n","            temperature=1.0,\n","            top_p=0.9)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1m123 12\u001b[0m9 683 494 604 481 363 552 468 567 487 581 555 531 481 534 478 528 446 481 513 416 505 637 519 479 524 467 542 589 500 563 390 536 516 523 496 497 482 520 466 542 617 544 489 480 486 434 481 533 491 544 515 474 461 546 336 542 378 509 583 434 588 548 540 517 489 543 454 495 465 486 603 524 501 501 488 506 497 488 489 528 449 493 494 488 507 489 364 509 394 501 471 498 473 506 477 528 578 503 541 473 385 478 507 477 535 438 338 479 514 520 536 508 509 479 476 498 539 458 520 369 420 547 428 578 598 426 599 522 378 524 508 581 560 518 351 567 445 495 528 431 469 561 516 519 498 569 488 513 488 601 165 333 581 430 527 460 415 501 640 426 549 523 535 482 494 518 324 533 528 507 591 447 523 446 607 563 469 585 546 556 511 451 547 505 445 506 468 473 466 553 501 540 547 440 388 439 507 585 467 546 578 550 500 556 513 466 487 525 447 545 506 516 534 475 471 400 531 588 540 442 584 466 514 487 445 479 536 464 488 501 515 515 537 521 547 503 524 431 409 538 471 485\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zjjEN2Tafhl2"},"source":["For bulk generation, you can generate a large amount of texts to a file and sort out the samples locally on your computer. The next cell will generate `num_files` files, each with `n` texts and whatever other parameters you would pass to `generate()`. The files can then be downloaded from the Files sidebar!\n","\n","You can rerun the cells as many times as you want for even more generated texts!"]},{"cell_type":"code","metadata":{"id":"Fa6p6arifSL0","colab":{"base_uri":"https://localhost:8080/","height":362,"referenced_widgets":["4f050c2bc02c4841a33f90cc6a02bacc","229e97fc3f3044ce822422c2a2447a39","bcf51d5fecee444ebbb6fe4fc077e7e9","ec51175c8bbd41f0934ccb15006452c4","e82a60196ca840ba9fde7fcaab322b8b","e3009893e58845f5a1bd631921f32e62","6204e958e12f4cde83fb1719c1630551","124b2727871f45fa9c250ace69e56300","6463d3bdaf134ff5944d335b7505844e","5b3554dd4eb8486bb9d5079d10b82950","f6dce16c05c8481a9394803928c59ebc","b6f567648d1142fd86ca16fcba8aa297","35b723c5289c4f59834133ffbc4aac73","786f685657d949f491f5b85b727a34ee","3508707863a94cb682c0bbd6de9682b2","a38268194b1d42cdad12fcf7aa2ba720","a01263a43ba84679a10b184b8b8b62fe","4bc450fd005d4769aaa745a94ce2a6e3","06edd28fd3424bf481135eb240a952fb","d5e39d3761a04e01934d3b68f6766ef9","28579590db664d3db5dd299f86d89687","2ebb28f4b07547d4ae42638638b7cc01","2ff342b1b23e46b18eefce4a2208493d","c42653e1ec904262881fd07733f5fff2","586d5cf1054846b586549b86013efafd","5581f66bb872463890720232663d730a","a479d17319fd42bc9fc7904d7a7ff55f","5b9010cc291a4b99bc86ba9b3e0725cf","28012133664b437d9fe23cf40075ab4d","c02c4826dcd14f4e83042bf7d7464c61","2002ad6b9f524b83b330f7409be54250","494d036247c5407d8479fa65e02fd25f","b9c126ac084e45f7a55b9435c2c9d2bd","5da581e7c4734f41a186c25b8d48c58f","db2190bbdbf04f1fae54032f61fef912","8d695275ac4c471aaf0910e749ea71d5","01250eb1d1b34f3f92453966048734d1","919e4cc6ea70431d8a1360e9bf592152","c67a09fc7d1a481fad6b764ebd7bec4d","7bb119334b554db89fa59dc67a26cdc8"]},"executionInfo":{"status":"ok","timestamp":1618797723044,"user_tz":420,"elapsed":149156,"user":{"displayName":"Max Woolf","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0NdDgxNKDV-wTnDDcuWVUlYIjr0GxEeo26q_7Aw=s64","userId":"10954469476206133987"}},"outputId":"c356cb76-bcf6-45dc-ad41-a00b03a8a847"},"source":["num_files = 5\n","\n","for _ in range(num_files):\n","  ai.generate_to_file(n=1000,\n","                     batch_size=50,\n","                     prompt=\"ROMEO:\",\n","                     temperature=1.0,\n","                     top_p=0.9)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["04/19/2021 01:59:34 — INFO — aitextgen — Generating 1,000 texts to ATG_20210419_015934_63053824.txt\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f050c2bc02c4841a33f90cc6a02bacc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["04/19/2021 02:00:04 — INFO — aitextgen — Generating 1,000 texts to ATG_20210419_020004_96905312.txt\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6463d3bdaf134ff5944d335b7505844e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["04/19/2021 02:00:33 — INFO — aitextgen — Generating 1,000 texts to ATG_20210419_020033_47861406.txt\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a01263a43ba84679a10b184b8b8b62fe","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["04/19/2021 02:01:03 — INFO — aitextgen — Generating 1,000 texts to ATG_20210419_020103_74636692.txt\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"586d5cf1054846b586549b86013efafd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["04/19/2021 02:01:33 — INFO — aitextgen — Generating 1,000 texts to ATG_20210419_020133_64281888.txt\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9c126ac084e45f7a55b9435c2c9d2bd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wmTXWNUygS5E"},"source":["# LICENSE\n","\n","MIT License\n","\n","Copyright (c) 2020-2021 Max Woolf\n","\n","Permission is hereby granted, free of charge, to any person obtaining a copy\n","of this software and associated documentation files (the \"Software\"), to deal\n","in the Software without restriction, including without limitation the rights\n","to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n","copies of the Software, and to permit persons to whom the Software is\n","furnished to do so, subject to the following conditions:\n","\n","The above copyright notice and this permission notice shall be included in all\n","copies or substantial portions of the Software.\n","\n","THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n","AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n","OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n","SOFTWARE."]}]}